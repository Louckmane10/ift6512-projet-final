\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{float}

\geometry{margin=2.5cm}

% Theorem environments
\newtheorem{definition}{Définition}[section]
\newtheorem{theorem}{Théorème}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemme}[section]
\newtheorem{corollary}{Corollaire}[section]
\newtheorem{remark}{Remarque}[section]
\newtheorem{example}{Exemple}[section]

% Algorithm translation
\floatname{algorithm}{Algorithme}
\renewcommand{\algorithmicrequire}{\textbf{Entrées:}}
\renewcommand{\algorithmicensure}{\textbf{Sorties:}}
\renewcommand{\algorithmicwhile}{\textbf{Tant que}}
\renewcommand{\algorithmicdo}{\textbf{faire}}
\renewcommand{\algorithmicif}{\textbf{Si}}
\renewcommand{\algorithmicthen}{\textbf{alors}}
\renewcommand{\algorithmicelse}{\textbf{Sinon}}
\renewcommand{\algorithmicend}{\textbf{Fin}}
\renewcommand{\algorithmicfor}{\textbf{Pour}}
\renewcommand{\algorithmicforall}{\textbf{Pour tout}}
\renewcommand{\algorithmicreturn}{\textbf{Retourner}}

% Code listings style
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{orange},
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    breaklines=true
}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\Var}{\text{Var}}
\newcommand{\argmin}{\text{argmin}}
\newcommand{\argmax}{\text{argmax}}

\title{\textbf{Apprentissage Distributionnellement Robuste \\avec Données Manquantes Stochastiques}\\[1em]
\Large Projet Final -- IFT6512 Programmation Stochastique}

\author{Louck\\
Université de Montréal\\
\texttt{louck@umontreal.ca}}

\date{Décembre 2025}

\begin{document}

\maketitle

\begin{abstract}
Ce projet s'attaque au problème de l'apprentissage supervisé en présence de données manquantes dont le mécanisme de génération est incertain ou mal spécifié. En diagnostic médical, le fait qu'un test soit prescrit dépend souvent de ce que le médecin suspecte --- créant un mécanisme MNAR (Missing Not At Random) fondamentalement non-identifiable. Pour faire face à cette incertitude, on formule le problème comme un programme stochastique distributionnellement robuste à deux étapes : la première étape décide quelles caractéristiques acquérir sous contrainte de budget, la seconde effectue la prédiction en se protégeant contre le pire cas dans un ensemble d'ambiguïté de Wasserstein. On développe un algorithme basé sur la Sample Average Approximation (SAA) et la reformulation duale du problème DRO. Les expériences numériques sur des données de diagnostic médical (Pima Diabetes, Heart Disease) montrent que l'approche DRO produit des politiques d'acquisition plus robustes aux variations du mécanisme de manquement, au prix d'une légère perte de performance moyenne lorsque le modèle est bien spécifié.
\end{abstract}

\newpage
\tableofcontents
\newpage

%##############################################################################
%##############################################################################
\part{Contexte et Fondements}
%##############################################################################
%##############################################################################

%==============================================================================
\section{Introduction}
\label{sec:introduction}
%==============================================================================

\subsection{Motivation et contexte applicatif}

Les données manquantes sont omniprésentes en apprentissage automatique. Dans beaucoup de situations, on peut s'en accommoder avec des méthodes d'imputation standard. Mais il existe des contextes où le mécanisme de manquement lui-même pose problème --- et le diagnostic médical en est l'exemple parfait.

Quand un médecin examine un patient, il ne prescrit pas tous les tests possibles. Il sélectionne ceux qui lui semblent pertinents en fonction des symptômes observés et de ses suspicions cliniques. Si le médecin prescrit une glycémie à jeun, c'est souvent parce qu'il suspecte un diabète. Autrement dit, le fait qu'une valeur soit mesurée ou non dépend de la valeur elle-même --- c'est le mécanisme MNAR (\textit{Missing Not At Random}).

Le problème fondamental avec le MNAR, c'est qu'il est non-identifiable : même avec un échantillon infini, on ne peut pas distinguer certains mécanismes MNAR de certains mécanismes MAR. Toute méthode d'imputation repose donc sur des hypothèses invérifiables.

Face à cette incertitude structurelle, l'optimisation distributionnellement robuste (DRO) offre un cadre naturel : au lieu de parier sur une distribution unique des données manquantes, on considère un ensemble de distributions plausibles et on optimise pour le pire cas.

\subsection{Le problème en bref}

Considérons un patient arrivant aux urgences. Le médecin dispose de certaines informations (âge, symptômes, signes vitaux) mais pas d'autres (glycémie, cholestérol, résultats d'imagerie). Il doit décider :
\begin{enumerate}
    \item \textbf{Quels tests prescrire ?} Chaque test a un coût (financier, temporel, inconfort pour le patient) et le budget est limité.
    \item \textbf{Comment prédire le diagnostic ?} Avec les informations disponibles (observées + acquises + imputées).
\end{enumerate}

La difficulté est que la valeur d'un test dépend de ce qu'on ne sait pas encore : si la glycémie est normale, le test de glycémie a peu de valeur; si elle est élevée, il est crucial. Or, le fait même que le test n'ait pas été prescrit auparavant peut indiquer que les médecins précédents n'ont pas suspecté de problème --- c'est l'essence du biais MNAR.

Notre approche traite ce problème en deux étapes :
\begin{itemize}
    \item \textbf{Étape 1 (ici et maintenant)} : Décider quelles caractéristiques acquérir, en anticipant l'incertitude sur leurs valeurs.
    \item \textbf{Étape 2 (recours)} : Après acquisition, utiliser les valeurs observées et imputer le reste, en se protégeant contre les pires cas plausibles.
\end{itemize}

\subsection{Contributions}

Ce projet apporte les contributions suivantes :
\begin{enumerate}
    \item \textbf{Formulation théorique.} Une formulation du problème d'apprentissage avec données manquantes comme programme stochastique DRO à deux étapes, intégrant une décision d'acquisition sous contrainte de budget. On montre comment l'ensemble d'ambiguïté de Wasserstein capture naturellement l'incertitude sur le mécanisme de manquement.
    
    \item \textbf{Algorithme SAA-DRO.} Un algorithme de résolution basé sur la Sample Average Approximation et la reformulation duale du problème DRO-Wasserstein. Pour les fonctions de perte lipschitziennes (comme la log-loss), cette reformulation se simplifie considérablement.
    
    \item \textbf{Analyse théorique.} Des résultats sur la complexité du problème (NP-difficulté), les garanties d'approximation de l'heuristique gloutonne, et la convergence de l'estimateur SAA.
    
    \item \textbf{Étude expérimentale.} Une étude expérimentale comparant l'approche DRO aux baselines classiques sur deux datasets médicaux (Pima Diabetes, Heart Disease), sous quatre mécanismes de manquement (MCAR, MAR, MNAR+, MNAR--).
    
    \item \textbf{Analyse de la valeur de l'information.} Une quantification de la valeur marginale de chaque caractéristique sous le critère robuste, et une comparaison avec le critère non-robuste.
\end{enumerate}

\subsection{Résultats principaux}

Les expériences numériques révèlent plusieurs résultats importants :

\begin{itemize}
    \item \textbf{DRO surpasse les baselines sous MNAR.} L'approche DRO réduit la log-loss de 7-9\% par rapport à l'approche non-robuste quand le mécanisme est MNAR, tout en ne perdant que 2\% sous MCAR.
    
    \item \textbf{Robustesse accrue.} L'écart de performance entre le meilleur et le pire mécanisme est réduit de 3$\times$ (de 0.076 à 0.026).
    
    \item \textbf{Rayon optimal identifié.} Le rayon d'ambiguïté $\epsilon \approx 0.10$ offre le meilleur compromis entre performance moyenne et robustesse.
    
    \item \textbf{Convergence rapide.} L'approximation SAA avec $N = 500$ scénarios suffit pour une erreur inférieure à 0.5\%.
    
    \item \textbf{Efficacité budgétaire.} L'approche DRO atteint la saturation de performance avec 18\% moins de budget que l'approche non-robuste.
\end{itemize}

\subsection{Organisation du rapport}

Le rapport est organisé comme suit :

\begin{itemize}
    \item \textbf{Section~\ref{sec:theorie} --- Fondements théoriques.} Présente la DRO, la distance de Wasserstein, les théorèmes de dualité, la taxonomie des données manquantes, et la formulation du problème à deux étapes.
    
    \item \textbf{Section~\ref{sec:methodologie} --- Méthodologie.} Détaille les algorithmes de génération de scénarios, d'évaluation de l'objectif DRO, d'optimisation combinatoire, et le pipeline SAA-DRO complet.
    
    \item \textbf{Section~\ref{sec:cadre_experimental} --- Cadre expérimental.} Décrit les datasets, les mécanismes de manquement simulés, les métriques, et les baselines.
    
    \item \textbf{Section~\ref{sec:resultats} --- Résultats numériques.} Présente les résultats des cinq expériences principales avec tableaux et analyses.
    
    \item \textbf{Section~\ref{sec:discussion} --- Discussion.} Interprète les résultats, discute les limites, et établit des connexions avec la littérature.
    
    \item \textbf{Section~\ref{sec:conclusion} --- Conclusion.} Synthétise les contributions et ouvre des perspectives.
\end{itemize}

Le code Julia complet est disponible en annexe et permet de reproduire toutes les expériences.

%==============================================================================
\section{Fondements Théoriques}
\label{sec:theorie}
%==============================================================================

Cette section présente les fondements mathématiques de notre approche. On commence par un aperçu historique de l'optimisation distributionnellement robuste, puis on détaille la théorie du transport optimal et la distance de Wasserstein. On établit ensuite les résultats de dualité fondamentaux pour les problèmes DRO-Wasserstein. Enfin, on formalise le problème des données manquantes et on montre comment la DRO offre un cadre naturel pour traiter l'incertitude sur le mécanisme de manquement.

\subsection{Optimisation sous incertitude : du stochastique au robuste}
\label{subsec:historique}

\subsubsection{Optimisation stochastique classique}

L'optimisation stochastique, initiée par Dantzig dans les années 1950, cherche à prendre des décisions optimales en présence d'incertitude. Le paradigme classique formule le problème comme :
\begin{equation}
    \min_{x \in \mathcal{X}} \; \E_P[f(x, \xi)]
\label{eq:stoch_classique}
\end{equation}
où $x \in \mathcal{X} \subseteq \R^n$ est la variable de décision, $\xi \in \Xi \subseteq \R^m$ est un vecteur aléatoire de distribution $P$, et $f : \mathcal{X} \times \Xi \to \R$ est la fonction de coût.

Ce paradigme repose sur une hypothèse forte : la distribution $P$ est connue exactement. En pratique, $P$ est estimée à partir d'un échantillon $\{\xi^1, \ldots, \xi^N\}$, ce qui introduit une erreur d'estimation. L'approche SAA (Sample Average Approximation) remplace l'espérance par une moyenne empirique :
\begin{equation}
    \min_{x \in \mathcal{X}} \; \frac{1}{N} \sum_{k=1}^{N} f(x, \xi^k)
\end{equation}

Sous des hypothèses de régularité, la solution SAA converge vers la solution du problème original quand $N \to \infty$. Cependant, pour $N$ fini, la solution peut être sensible à l'échantillon particulier utilisé, et cette sensibilité s'aggrave quand la distribution estimée $\hat{P}_N$ diffère significativement de la vraie distribution $P^*$.

\subsubsection{Optimisation robuste}

L'optimisation robuste, développée par Ben-Tal, El Ghaoui et Nemirovski dans les années 1990-2000, adopte une approche radicalement différente : au lieu de supposer une distribution, on considère un ensemble d'incertitude $\mathcal{U}$ et on optimise pour le pire cas :
\begin{equation}
    \min_{x \in \mathcal{X}} \; \max_{\xi \in \mathcal{U}} \; f(x, \xi)
\end{equation}

Cette approche offre des garanties déterministes mais peut être très conservatrice : le pire cas peut correspondre à un scénario extrêmement improbable.

\subsubsection{Optimisation distributionnellement robuste}

L'optimisation distributionnellement robuste (DRO) offre un compromis entre les approches stochastique et robuste. Au lieu de considérer une distribution unique ou tous les scénarios possibles, on considère un ensemble $\mathcal{P}$ de distributions plausibles :
\begin{equation}
\boxed{
    \min_{x \in \mathcal{X}} \; \sup_{P \in \mathcal{P}} \; \E_P[f(x, \xi)]
}
\label{eq:dro_general}
\end{equation}

L'ensemble $\mathcal{P}$, appelé \textit{ensemble d'ambiguïté}, encode notre incertitude sur la vraie distribution. Le problème~\eqref{eq:dro_general} peut être vu comme un jeu à deux joueurs : le décideur choisit $x$ pour minimiser le coût, puis la ``nature'' choisit la distribution la plus défavorable dans $\mathcal{P}$.

Cette formulation remonte aux travaux de Scarf (1958) sur le problème du vendeur de journaux, mais a connu un renouveau spectaculaire depuis les années 2010 grâce à de nouveaux outils computationnels et théoriques.

\subsection{Ensembles d'ambiguïté : un panorama}
\label{subsec:ambiguity_sets}

Le choix de l'ensemble d'ambiguïté $\mathcal{P}$ est crucial. Il doit être suffisamment grand pour contenir la vraie distribution avec haute probabilité, mais suffisamment petit pour que le problème ne soit pas trop conservateur. On distingue trois grandes familles.

\subsubsection{Ensembles basés sur les moments}

L'approche historique définit $\mathcal{P}$ par des contraintes sur les moments :
\begin{equation}
    \mathcal{P}_{\text{mom}} = \left\{ P : \E_P[\xi] = \mu, \; \E_P[(\xi - \mu)(\xi - \mu)^\top] \preceq \Sigma \right\}
\end{equation}

\begin{example}[Problème de Scarf]
Pour le problème du vendeur de journaux avec demande $\xi$ de moyenne $\mu$ et variance $\sigma^2$, Scarf (1958) a montré que la quantité optimale robuste est :
\begin{equation}
    q^* = \mu + \sigma \sqrt{\frac{p}{2(c_u + c_o)}}
\end{equation}
où $c_u$ est le coût de sous-stock et $c_o$ le coût de sur-stock.
\end{example}

\textbf{Avantages} : Interprétabilité, tractabilité (reformulation en SDP).\\
\textbf{Inconvénients} : Peut être trop conservateur (le pire cas peut avoir une forme très différente des distributions réalistes).

\subsubsection{Ensembles basés sur les $\phi$-divergences}

Une deuxième famille utilise les divergences statistiques pour définir un voisinage autour d'une distribution de référence $P_0$ :
\begin{equation}
    \mathcal{P}_{\phi} = \left\{ P \ll P_0 : D_\phi(P \| P_0) \leq \epsilon \right\}
\end{equation}

où $D_\phi$ est une $\phi$-divergence :
\begin{equation}
    D_\phi(P \| P_0) = \int \phi\left(\frac{dP}{dP_0}\right) dP_0
\end{equation}

Les cas particuliers importants incluent :
\begin{itemize}
    \item Kullback-Leibler : $\phi(t) = t \log t - t + 1$
    \item $\chi^2$ : $\phi(t) = (t-1)^2$
    \item Variation totale : $\phi(t) = |t - 1|$
\end{itemize}

\textbf{Avantages} : Lien avec la théorie de l'information, garanties de généralisation.\\
\textbf{Inconvénients} : Requiert $P \ll P_0$ (même support), peut être insensible à la géométrie de l'espace.

\subsubsection{Ensembles basés sur la distance de Wasserstein}

La troisième famille, qui a émergé plus récemment, utilise la distance de Wasserstein :
\begin{equation}
    \mathcal{P}_{\epsilon}^W = \left\{ P : W_p(P, P_0) \leq \epsilon \right\}
\end{equation}

Cette approche présente plusieurs avantages qui l'ont rendue très populaire :
\begin{enumerate}
    \item Elle ne requiert pas que $P$ et $P_0$ aient le même support.
    \item Elle tient compte de la géométrie de l'espace des données.
    \item Elle mène à des reformulations tractables pour de nombreuses classes de problèmes.
    \item Elle possède des propriétés statistiques attrayantes (concentration, généralisation).
\end{enumerate}

\subsection{Transport optimal et distance de Wasserstein}
\label{subsec:wasserstein}

La distance de Wasserstein est issue de la théorie du transport optimal, initiée par Monge (1781) et développée par Kantorovich (1942).

\subsubsection{Le problème de Monge}

Le problème original de Monge consiste à transporter une distribution de masse $P$ vers une distribution $Q$ en minimisant le coût total de transport :
\begin{equation}
    \inf_{T : T_\# P = Q} \int \|x - T(x)\|^p \, dP(x)
\end{equation}
où $T : \Xi \to \Xi$ est une application de transport et $T_\# P$ désigne la mesure image de $P$ par $T$.

Ce problème est difficile car il impose que chaque point source soit envoyé vers un unique point destination (transport déterministe).

\subsubsection{La relaxation de Kantorovich}

Kantorovich a proposé une relaxation permettant de ``diviser'' la masse d'un point source vers plusieurs destinations. On cherche un plan de transport $\gamma$ sur $\Xi \times \Xi$ :
\begin{equation}
    W_p^p(P, Q) = \inf_{\gamma \in \Gamma(P, Q)} \int_{\Xi \times \Xi} \|\xi - \xi'\|^p \, d\gamma(\xi, \xi')
\label{eq:wasserstein_def}
\end{equation}
où $\Gamma(P, Q)$ est l'ensemble des couplages de marginales $P$ et $Q$ :
\begin{equation}
    \Gamma(P, Q) = \left\{ \gamma \in \mathcal{M}_+(\Xi \times \Xi) : \pi_{1\#}\gamma = P, \; \pi_{2\#}\gamma = Q \right\}
\end{equation}

\begin{definition}[Distance de Wasserstein]
Pour $p \geq 1$, la distance de Wasserstein d'ordre $p$ entre deux mesures de probabilité $P$ et $Q$ sur $(\Xi, \|\cdot\|)$ est :
\begin{equation}
    W_p(P, Q) = \left( \inf_{\gamma \in \Gamma(P, Q)} \int \|\xi - \xi'\|^p \, d\gamma(\xi, \xi') \right)^{1/p}
\end{equation}
\end{definition}

\subsubsection{Propriétés fondamentales}

\begin{theorem}[Propriétés de $W_p$]
Soit $\mathcal{P}_p(\Xi)$ l'espace des mesures de probabilité sur $\Xi$ ayant un moment d'ordre $p$ fini. Alors :
\begin{enumerate}
    \item $W_p$ est une distance sur $\mathcal{P}_p(\Xi)$.
    \item La convergence selon $W_p$ est équivalente à la convergence faible plus la convergence des moments d'ordre $p$.
    \item Pour $p = 1$ et $\Xi = \R$, on a la formule explicite :
    \begin{equation}
        W_1(P, Q) = \int_0^1 |F_P^{-1}(u) - F_Q^{-1}(u)| \, du
    \end{equation}
    où $F_P^{-1}$ et $F_Q^{-1}$ sont les fonctions quantiles.
\end{enumerate}
\end{theorem}

\begin{proposition}[Wasserstein entre empiriques]
Soit $\hat{P}_N = \frac{1}{N}\sum_{k=1}^N \delta_{\xi^k}$ la mesure empirique et $\hat{Q}_M = \frac{1}{M}\sum_{j=1}^M \delta_{\zeta^j}$. Alors :
\begin{equation}
    W_p^p(\hat{P}_N, \hat{Q}_M) = \min_{\Pi \in \mathcal{T}} \sum_{k,j} \Pi_{kj} \|\xi^k - \zeta^j\|^p
\end{equation}
où $\mathcal{T}$ est l'ensemble des matrices bistochastiques (généralisées) de dimensions appropriées. Ce problème se résout en $O((N+M)^3 \log(N+M))$ par programmation linéaire.
\end{proposition}

\subsubsection{Dualité de Kantorovich}

Un résultat fondamental est la formulation duale du problème de transport optimal :

\begin{theorem}[Dualité de Kantorovich-Rubinstein]
Pour $p = 1$ :
\begin{equation}
    W_1(P, Q) = \sup_{f : \|f\|_{\text{Lip}} \leq 1} \left\{ \E_P[f(\xi)] - \E_Q[f(\xi)] \right\}
\end{equation}
où $\|f\|_{\text{Lip}} = \sup_{x \neq y} \frac{|f(x) - f(y)|}{\|x - y\|}$ est la constante de Lipschitz de $f$.
\end{theorem}

Cette dualité est à la base de nombreuses applications, notamment les réseaux adversariaux génératifs (Wasserstein GAN).

\subsubsection{Concentration de la mesure empirique}

Un résultat crucial pour la DRO est le taux de convergence de $\hat{P}_N$ vers $P^*$ selon $W_p$ :

\begin{theorem}[Concentration de Wasserstein]
\label{thm:concentration}
Soit $P^*$ une distribution sur $\R^d$ avec un moment d'ordre $p+\delta$ fini pour un $\delta > 0$. Alors, avec probabilité au moins $1 - \alpha$ :
\begin{equation}
    W_p(P^*, \hat{P}_N) \leq \epsilon_N(\alpha)
\end{equation}
où :
\begin{equation}
    \epsilon_N(\alpha) = \begin{cases}
        C \cdot N^{-1/\max(d, 2)} \cdot \log(1/\alpha)^{1/p} & \text{si } d \neq 2p \\
        C \cdot N^{-1/2} \cdot \log(N)^{1/p} \cdot \log(1/\alpha)^{1/p} & \text{si } d = 2p
    \end{cases}
\end{equation}
et $C$ dépend de $P^*$, $d$ et $p$.
\end{theorem}

Ce théorème montre que si l'on choisit $\epsilon \geq \epsilon_N(\alpha)$, alors $P^* \in \mathcal{P}_\epsilon^W$ avec probabilité au moins $1 - \alpha$. C'est la garantie fondamentale qui justifie l'utilisation de la DRO-Wasserstein.

\begin{remark}[Malédiction de la dimension]
Le taux de convergence $N^{-1/d}$ (pour $d > 2$) souffre de la malédiction de la dimension : en grande dimension, il faut un échantillon exponentiellement grand pour que $\epsilon_N$ soit petit. Cependant, si les données sont concentrées près d'une variété de dimension intrinsèque $d_{\text{int}} \ll d$, le taux effectif est $N^{-1/d_{\text{int}}}$.
\end{remark}

\subsection{DRO avec ambiguïté de Wasserstein : résultats de dualité}
\label{subsec:dro_wasserstein}

On s'intéresse maintenant au problème :
\begin{equation}
    \sup_{P : W_p(P, P_0) \leq \epsilon} \E_P[\ell(\xi)]
\label{eq:dro_wasserstein}
\end{equation}
où $\ell : \Xi \to \R$ est une fonction de perte et $P_0$ est la distribution de référence (typiquement empirique).

\subsubsection{Théorème de dualité forte}

Le résultat central qui rend le problème~\eqref{eq:dro_wasserstein} tractable est le suivant :

\begin{theorem}[Dualité DRO-Wasserstein]
\label{thm:dro_dual}
Soit $\ell : \Xi \to \R$ une fonction mesurable bornée supérieurement, et $P_0$ une distribution de probabilité sur $\Xi$. Alors :
\begin{equation}
\boxed{
    \sup_{P : W_p(P, P_0) \leq \epsilon} \E_P[\ell(\xi)] = \inf_{\lambda \geq 0} \left\{ \lambda \epsilon^p + \E_{P_0}\left[ \sup_{\xi' \in \Xi} \left\{ \ell(\xi') - \lambda \|\xi' - \xi\|^p \right\} \right] \right\}
}
\label{eq:dro_dual_formula}
\end{equation}
De plus, si $\ell$ est semi-continue supérieurement et $\Xi$ est compact, l'infimum sur $\lambda$ est atteint.
\end{theorem}

\begin{proof}[Esquisse de preuve]
On introduit le Lagrangien associé à la contrainte $W_p(P, P_0) \leq \epsilon$ :
\begin{equation}
    \mathcal{L}(P, \lambda) = \E_P[\ell(\xi)] - \lambda \left( W_p^p(P, P_0) - \epsilon^p \right)
\end{equation}

Le problème primal est $\sup_P \inf_{\lambda \geq 0} \mathcal{L}(P, \lambda)$.

Par le min-max de Sion (applicable car l'espace des distributions est convexe et $\mathcal{L}$ est affine en $P$ et $\lambda$), on a :
\begin{equation}
    \sup_P \inf_{\lambda \geq 0} \mathcal{L}(P, \lambda) = \inf_{\lambda \geq 0} \sup_P \mathcal{L}(P, \lambda)
\end{equation}

Pour $\lambda$ fixé, le problème intérieur $\sup_P \mathcal{L}(P, \lambda)$ se réécrit :
\begin{align}
    \sup_P \left\{ \E_P[\ell(\xi)] - \lambda W_p^p(P, P_0) \right\} &= \sup_P \sup_{\gamma \in \Gamma(P, P_0)} \left\{ \E_P[\ell(\xi)] - \lambda \int \|\xi - \xi'\|^p d\gamma \right\} \\
    &= \sup_{\gamma} \left\{ \int \left( \ell(\xi) - \lambda \|\xi - \xi'\|^p \right) d\gamma(\xi, \xi') \right\}
\end{align}

En optimisant sur $\gamma$ à $\xi'$ fixé (marginal en $P_0$), on obtient :
\begin{equation}
    = \E_{P_0}\left[ \sup_{\xi} \left\{ \ell(\xi) - \lambda \|\xi - \xi'\|^p \right\} \right]
\end{equation}

Le terme $\lambda \epsilon^p$ vient de la contrainte.
\end{proof}

\subsubsection{Interprétation du dual}

La formule duale~\eqref{eq:dro_dual_formula} a une interprétation élégante :
\begin{itemize}
    \item $\lambda$ est un ``prix'' associé à la robustesse : plus $\lambda$ est grand, plus on pénalise le transport loin des données observées.
    \item Le terme $\sup_{\xi'} \{ \ell(\xi') - \lambda \|\xi' - \xi\|^p \}$ est la \textit{transformation de Moreau-Yosida} de $\ell$ (ou sa c-transformée).
    \item L'infimum sur $\lambda$ réalise le meilleur compromis entre robustesse et adaptation aux données.
\end{itemize}

\subsubsection{Cas des fonctions lipschitziennes}

Lorsque $\ell$ est lipschitzienne de constante $L$, le supremum interne admet une forme simple :

\begin{proposition}[Cas lipschitzien]
\label{prop:lipschitz}
Si $\ell$ est $L$-lipschitzienne, alors pour $p = 1$ :
\begin{equation}
    \sup_{\xi'} \left\{ \ell(\xi') - \lambda \|\xi' - \xi\| \right\} = \begin{cases}
        +\infty & \text{si } \lambda < L \\
        \ell(\xi) & \text{si } \lambda \geq L
    \end{cases}
\end{equation}
En conséquence :
\begin{equation}
    \sup_{P : W_1(P, P_0) \leq \epsilon} \E_P[\ell(\xi)] = \E_{P_0}[\ell(\xi)] + L \epsilon
\end{equation}
\end{proposition}

\begin{proof}
Pour $\lambda \geq L$, on a par lipschitzianité :
\begin{equation}
    \ell(\xi') - \lambda \|\xi' - \xi\| \leq \ell(\xi) + L\|\xi' - \xi\| - \lambda \|\xi' - \xi\| \leq \ell(\xi)
\end{equation}
avec égalité en $\xi' = \xi$.

Pour $\lambda < L$, on peut faire tendre $\|\xi' - \xi\| \to \infty$ dans une direction où $\ell$ croît à taux $L$, ce qui donne $+\infty$.
\end{proof}

Cette proposition montre que pour les fonctions lipschitziennes, la DRO-Wasserstein se réduit à une régularisation additive : on ajoute $L\epsilon$ à l'espérance nominale.

\subsubsection{Cas de l'ordre $p = 2$}

Pour $p = 2$, le supremum interne peut se calculer explicitement lorsque $\ell$ est quadratique ou convexe :

\begin{proposition}[Cas quadratique]
Si $\ell(\xi) = \frac{1}{2}\|\xi - a\|^2$ et $p = 2$, alors :
\begin{equation}
    \sup_{\xi'} \left\{ \frac{1}{2}\|\xi' - a\|^2 - \lambda \|\xi' - \xi\|^2 \right\} = \begin{cases}
        +\infty & \text{si } \lambda < \frac{1}{2} \\
        \frac{1}{2(2\lambda - 1)} \|a - \xi\|^2 + \frac{\lambda}{2\lambda - 1} \|\xi - a\|^2 & \text{si } \lambda > \frac{1}{2}
    \end{cases}
\end{equation}
\end{proposition}

\subsubsection{Lien avec la régularisation}

Un des résultats les plus remarquables de la DRO-Wasserstein est son lien avec la régularisation des modèles d'apprentissage :

\begin{theorem}[Équivalence DRO-Régularisation]
\label{thm:regularization}
Pour un problème d'apprentissage avec perte $\ell(y, f_\theta(x))$ paramétrée par $\theta$, la solution DRO-Wasserstein est équivalente à une régularisation sur les gradients :
\begin{equation}
    \min_\theta \sup_{P : W_1(P, \hat{P}_N) \leq \epsilon} \E_P[\ell(y, f_\theta(x))] \approx \min_\theta \left\{ \frac{1}{N} \sum_{k=1}^N \ell(y^k, f_\theta(x^k)) + \epsilon \cdot \|\nabla_x f_\theta\| \right\}
\end{equation}

Cette régularisation favorise les modèles avec de petits gradients par rapport aux entrées, ce qui correspond à la notion de robustesse adversariale.
\end{theorem}

\begin{proof}
Appliquons le Théorème~\ref{thm:dro_dual} avec $P_0 = \hat{P}_N = \frac{1}{N}\sum_{k=1}^N \delta_{(x^k, y^k)}$ la distribution empirique. Pour $p = 1$ :
\begin{equation}
    \sup_{P : W_1(P, \hat{P}_N) \leq \epsilon} \E_P[\ell(\cdot)] = \inf_{\lambda \geq 0} \left\{ \lambda \epsilon + \frac{1}{N}\sum_{k=1}^N \sup_{(x', y')} \left\{ \ell(y', f_\theta(x')) - \lambda \|(x', y') - (x^k, y^k)\| \right\} \right\}
\end{equation}

Si $\ell(y', f_\theta(x'))$ est $L$-lipschitzienne en $(x', y')$, par la Proposition~\ref{prop:lipschitz}, le supremum vaut $\ell(y^k, f_\theta(x^k))$ pour $\lambda \geq L$. En optimisant sur $\lambda$, le minimum est atteint en $\lambda^* = L$, d'où :
\begin{equation}
    \sup_{P : W_1(P, \hat{P}_N) \leq \epsilon} \E_P[\ell] = \frac{1}{N}\sum_{k=1}^N \ell(y^k, f_\theta(x^k)) + L \epsilon
\end{equation}

Puisque $L = \|\nabla_{(x,y)} \ell(y, f_\theta(x))\|_{\infty}$ dépend de $\theta$ via le gradient $\nabla_x f_\theta$, minimiser l'objectif DRO revient à minimiser la perte empirique plus un terme de régularisation proportionnel à la norme du gradient du modèle.
\end{proof}

\begin{remark}[Connexion avec l'adversarial training]
Cette équivalence explique pourquoi la DRO-Wasserstein est liée à l'entraînement adversarial : optimiser pour le pire cas dans une boule de Wasserstein revient à se protéger contre des perturbations adversariales des entrées. Les modèles ainsi entraînés ont des surfaces de décision plus lisses.
\end{remark}

\subsubsection{Calcul explicite pour la log-loss}

Dans notre contexte de classification binaire, la fonction de perte est la log-loss :
\begin{equation}
    \ell(y, p) = -y \log(p) - (1-y) \log(1-p)
\end{equation}
où $p = f_\theta(x) \in (0, 1)$ est la probabilité prédite.

\begin{proposition}[Constante de Lipschitz de la log-loss]
\label{prop:logloss_lipschitz}
Pour un modèle logistique $f_\theta(x) = \sigma(\theta^\top x)$ avec $\sigma(z) = 1/(1+e^{-z})$, la constante de Lipschitz de la log-loss par rapport à $x$ est :
\begin{equation}
    L = \|\theta\| \cdot \max_{z \in \R} \left| \frac{d}{dz} \ell(y, \sigma(z)) \right| = \|\theta\|
\end{equation}
La constante est atteinte pour $\sigma(z) = 0.5$, i.e., sur la frontière de décision.
\end{proposition}

\begin{proof}
Le gradient de la log-loss composée avec le modèle logistique est :
\begin{equation}
    \nabla_x \ell(y, f_\theta(x)) = (f_\theta(x) - y) \cdot \theta
\end{equation}

La norme est $\|(f_\theta(x) - y) \cdot \theta\| = |f_\theta(x) - y| \cdot \|\theta\|$.

Puisque $f_\theta(x) \in (0, 1)$ et $y \in \{0, 1\}$, on a $|f_\theta(x) - y| \leq 1$, avec égalité quand $f_\theta(x) \to 0$ et $y = 1$ (ou inversement). En pratique, pour des prédictions raisonnables, $|f_\theta(x) - y| \approx 0.5$ en moyenne, d'où $L \approx \|\theta\|$.
\end{proof}

\begin{corollary}[Objectif DRO pour la log-loss]
Pour le problème de classification avec log-loss et modèle logistique :
\begin{equation}
    R_{\text{DRO}}(\mathbf{z}) = \|\theta\| \cdot \epsilon + \frac{1}{N} \sum_{k=1}^N \ell(y, f_\theta(\tilde{x}^k(\mathbf{z})))
\end{equation}
Le terme de robustesse $\|\theta\| \cdot \epsilon$ est une constante indépendante de $\mathbf{z}$ pour le classifieur $\theta$ fixé. Cependant, la variance des scénarios $\tilde{x}^k$ dépend de $\mathbf{z}$.
\end{corollary}

\subsubsection{Reformulation computationnelle}

Pour l'implémentation, on utilise l'approximation SAA avec $N$ scénarios. La reformulation duale devient :

\begin{proposition}[Reformulation SAA-DRO]
\label{prop:saa_reformulation}
Pour $N$ scénarios $\{\boldsymbol{\xi}^1, \ldots, \boldsymbol{\xi}^N\}$ tirés de $P_0$ :
\begin{equation}
    \hat{R}_{\text{DRO}}^N(\mathbf{z}) = \inf_{\lambda \geq L} \left\{ \lambda \epsilon^p + \frac{1}{N} \sum_{k=1}^N \ell(y, f_\theta(\tilde{x}^k(\mathbf{z}, \boldsymbol{\xi}^k))) \right\}
\end{equation}

Si $\ell$ est $L$-lipschitzienne, l'infimum est atteint en $\lambda^* = L$, et :
\begin{equation}
\boxed{
    \hat{R}_{\text{DRO}}^N(\mathbf{z}) = L \cdot \epsilon^p + \frac{1}{N} \sum_{k=1}^N \ell(y, f_\theta(\tilde{x}^k(\mathbf{z}, \boldsymbol{\xi}^k)))
}
\label{eq:saa_dro_formula}
\end{equation}
\end{proposition}

Cette formule est la base de notre implémentation. Elle montre que l'évaluation de l'objectif DRO se réduit à :
\begin{enumerate}
    \item Calculer la constante de Lipschitz $L$ une fois.
    \item Évaluer la perte moyenne sur $N$ scénarios (standard).
    \item Ajouter le terme de pénalité $L \cdot \epsilon^p$.
\end{enumerate}

\subsection{Garanties de généralisation}
\label{subsec:generalization}

Un avantage majeur de la DRO-Wasserstein est qu'elle fournit des garanties de généralisation naturelles.

\subsubsection{Borne de généralisation}

\begin{theorem}[Généralisation DRO]
\label{thm:generalization}
Soit $\hat{P}_N$ la distribution empirique et $P^*$ la vraie distribution. Si l'on choisit $\epsilon \geq \epsilon_N(\alpha)$ selon le Théorème~\ref{thm:concentration}, alors avec probabilité au moins $1 - \alpha$ :
\begin{equation}
    \E_{P^*}[\ell(\xi)] \leq \sup_{P : W_p(P, \hat{P}_N) \leq \epsilon} \E_P[\ell(\xi)]
\end{equation}

En d'autres termes, l'objectif DRO est un majorant (avec haute probabilité) du vrai risque.
\end{theorem}

\begin{proof}
Par le Théorème~\ref{thm:concentration}, $W_p(P^*, \hat{P}_N) \leq \epsilon$ avec probabilité $\geq 1 - \alpha$. Donc $P^* \in \mathcal{P}_\epsilon$, et :
\begin{equation}
    \E_{P^*}[\ell(\xi)] \leq \sup_{P \in \mathcal{P}_\epsilon} \E_P[\ell(\xi)]
\end{equation}
\end{proof}

\subsubsection{Compromis biais-variance robuste}

La DRO-Wasserstein réalise un compromis entre :
\begin{itemize}
    \item \textbf{Biais} : Si $\epsilon$ est trop petit, l'ensemble $\mathcal{P}_\epsilon$ peut ne pas contenir $P^*$, et l'objectif DRO sous-estime le vrai risque.
    \item \textbf{Variance/Conservatisme} : Si $\epsilon$ est trop grand, l'objectif DRO surestime le vrai risque (trop conservateur).
\end{itemize}

Le choix optimal de $\epsilon$ dépend de $N$ et de la dimension $d$, comme indiqué par le Théorème~\ref{thm:concentration}.

\subsubsection{Choix optimal de $\epsilon$}

\begin{theorem}[Choix data-driven de $\epsilon$]
\label{thm:epsilon_choice}
Pour garantir que $P^* \in \mathcal{P}_\epsilon$ avec probabilité $1 - \alpha$, on peut choisir :
\begin{equation}
    \epsilon_N^*(\alpha) = \begin{cases}
        c_1 \cdot N^{-1/d} \cdot (\log N + \log(1/\alpha))^{1/p} & \text{si } d \geq 3 \\
        c_2 \cdot N^{-1/2} \cdot \sqrt{\log(1/\alpha)} & \text{si } d \leq 2
    \end{cases}
\end{equation}
où les constantes $c_1, c_2$ dépendent des moments de $P^*$.
\end{theorem}

\begin{remark}[Calibration pratique]
En pratique, les constantes $c_1, c_2$ sont inconnues. On utilise plutôt la validation croisée :
\begin{enumerate}
    \item Séparer les données en $K$ folds.
    \item Pour chaque $\epsilon$ dans une grille, évaluer la performance sur les folds de validation.
    \item Choisir $\epsilon^*$ qui minimise le risque pire cas sur les folds.
\end{enumerate}

Cette approche est implementée dans l'Algorithme~\ref{alg:cv_epsilon} de la Section~\ref{subsec:calibrage}.
\end{remark}

\subsubsection{Garantie out-of-sample}

\begin{theorem}[Borne out-of-sample]
\label{thm:out_of_sample}
Soit $\hat{\mathbf{z}}_N = \argmin_{\mathbf{z}} \hat{R}_N^{\text{DRO}}(\mathbf{z})$ la solution SAA-DRO avec rayon $\epsilon \geq \epsilon_N(\alpha)$. Alors, avec probabilité au moins $1 - 2\alpha$ :
\begin{equation}
    \E_{P^*}[\ell(y, f_\theta(\tilde{x}(\hat{\mathbf{z}}_N, \boldsymbol{\xi})))] \leq \hat{R}_N^{\text{DRO}}(\hat{\mathbf{z}}_N) + O\left(\sqrt{\frac{\log(1/\alpha)}{N}}\right)
\end{equation}

En d'autres termes, l'objectif DRO évalué sur l'échantillon est un bon prédicteur de la performance réelle.
\end{theorem}

\begin{proof}[Esquisse]
Par le Théorème~\ref{thm:generalization}, $\E_{P^*}[\ell] \leq R_{\text{DRO}}(\mathbf{z})$ pour tout $\mathbf{z}$. Par le Théorème~\ref{thm:rate}, $|R_{\text{DRO}}(\mathbf{z}) - \hat{R}_N^{\text{DRO}}(\mathbf{z})| = O(N^{-1/2})$. En combinant et en appliquant une union bound :
\begin{align}
    \E_{P^*}[\ell(\hat{\mathbf{z}}_N)] &\leq R_{\text{DRO}}(\hat{\mathbf{z}}_N) \\
    &\leq \hat{R}_N^{\text{DRO}}(\hat{\mathbf{z}}_N) + O(N^{-1/2}\sqrt{\log(1/\alpha)})
\end{align}
\end{proof}

Ce théorème est important car il justifie l'utilisation de l'objectif DRO comme critère de sélection : une solution avec un bon objectif DRO aura aussi une bonne performance réelle.

\subsection{Données manquantes : taxonomie et modélisation}
\label{subsec:missing_data}

On formalise maintenant le problème des données manquantes, qui constitue la source d'incertitude dans notre application.

\subsubsection{Notations}

Soit $\mathbf{X} = (X_1, \ldots, X_d) \in \R^d$ un vecteur de caractéristiques et $Y \in \{0, 1\}$ une variable cible. On observe :
\begin{itemize}
    \item Un masque de manquement $\mathbf{M} = (M_1, \ldots, M_d) \in \{0, 1\}^d$ où $M_j = 1$ indique que $X_j$ est manquant.
    \item Les valeurs observées $\mathbf{X}^{\text{obs}} = \{X_j : M_j = 0\}$.
    \item On ne connaît pas les valeurs manquantes $\mathbf{X}^{\text{miss}} = \{X_j : M_j = 1\}$.
\end{itemize}

On note $P(\mathbf{X}, Y, \mathbf{M})$ la distribution jointe complète.

\subsubsection{Taxonomie de Rubin}

La classification des mécanismes de manquement, due à Rubin (1976), est fondée sur la dépendance entre $\mathbf{M}$ et $\mathbf{X}$.

\begin{definition}[Mécanismes de manquement]
\label{def:missing_mechanisms}
\begin{enumerate}
    \item \textbf{MCAR (Missing Completely At Random)} : Le manquement est indépendant des données.
    \begin{equation}
        P(\mathbf{M} | \mathbf{X}, Y) = P(\mathbf{M})
    \end{equation}
    
    \item \textbf{MAR (Missing At Random)} : Le manquement dépend seulement des valeurs observées.
    \begin{equation}
        P(\mathbf{M} | \mathbf{X}, Y) = P(\mathbf{M} | \mathbf{X}^{\text{obs}}, Y)
    \end{equation}
    
    \item \textbf{MNAR (Missing Not At Random)} : Le manquement dépend des valeurs manquantes elles-mêmes.
    \begin{equation}
        P(\mathbf{M} | \mathbf{X}, Y) \text{ dépend de } \mathbf{X}^{\text{miss}}
    \end{equation}
\end{enumerate}
\end{definition}

\begin{example}[Diagnostic médical]
Dans le contexte du diagnostic du diabète :
\begin{itemize}
    \item \textbf{MCAR} : Un technicien de laboratoire renverse accidentellement certains échantillons (indépendant des valeurs).
    \item \textbf{MAR} : Les patients âgés refusent plus souvent certains examens invasifs (dépend de l'âge observé).
    \item \textbf{MNAR} : Le médecin prescrit un test de glycémie quand il suspecte un diabète, donc quand il pense que la glycémie pourrait être élevée. Les valeurs normales sont moins souvent mesurées.
\end{itemize}
\end{example}

\subsubsection{Ignorabilité et vraisemblance}

Sous MAR (ou MCAR), le mécanisme de manquement est dit \textit{ignorable} pour l'inférence sur $P(\mathbf{X}, Y)$ :

\begin{proposition}[Ignorabilité]
Si le mécanisme est MAR et les paramètres du modèle de données sont distincts des paramètres du modèle de manquement (distinctness), alors la vraisemblance observée se factorise :
\begin{equation}
    L(\theta | \mathbf{X}^{\text{obs}}, \mathbf{M}) \propto L(\theta | \mathbf{X}^{\text{obs}})
\end{equation}
et on peut ignorer le mécanisme de manquement pour l'estimation de $\theta$.
\end{proposition}

Cette propriété justifie les méthodes d'imputation classiques (moyenne, régression, EM) sous MAR.

\subsubsection{Non-identifiabilité du MNAR}

Le problème fondamental du MNAR est la non-identifiabilité :

\begin{theorem}[Non-identifiabilité]
\label{thm:non_identifiability}
Soit $P_{\text{obs}}(\mathbf{X}^{\text{obs}}, \mathbf{M})$ la distribution observée. Il existe en général une infinité de modèles $(\tilde{P}_{\mathbf{X}}, \tilde{P}_{\mathbf{M}|\mathbf{X}})$ compatibles avec $P_{\text{obs}}$, dont certains sont MAR et d'autres MNAR. Plus précisément :
\begin{equation}
    P_{\text{obs}}(\mathbf{X}^{\text{obs}}, \mathbf{M}) = \int P(\mathbf{X}^{\text{obs}}, \mathbf{X}^{\text{miss}}) \cdot P(\mathbf{M} | \mathbf{X}^{\text{obs}}, \mathbf{X}^{\text{miss}}) \, d\mathbf{X}^{\text{miss}}
\end{equation}
Cette intégrale ne détermine pas de façon unique la décomposition.
\end{theorem}

\begin{proof}[Esquisse]
Pour tout modèle $(P_{\mathbf{X}}, P_{\mathbf{M}|\mathbf{X}})$ compatible, on peut construire un autre modèle $(\tilde{P}_{\mathbf{X}}, \tilde{P}_{\mathbf{M}|\mathbf{X}})$ avec :
\begin{equation}
    \tilde{P}(\mathbf{X}^{\text{miss}} | \mathbf{X}^{\text{obs}}, \mathbf{M}) = P(\mathbf{X}^{\text{miss}} | \mathbf{X}^{\text{obs}}, \mathbf{M}) \cdot \frac{g(\mathbf{X}^{\text{miss}})}{\E[g(\mathbf{X}^{\text{miss}}) | \mathbf{X}^{\text{obs}}, \mathbf{M}]}
\end{equation}
pour toute fonction $g > 0$. Ce nouveau modèle produit les mêmes observations mais avec un mécanisme de manquement différent.
\end{proof}

\begin{corollary}[Impossibilité de test]
Aucun test statistique ne peut distinguer MAR de MNAR à partir des données observées seules.
\end{corollary}

Cette impossibilité fondamentale justifie l'approche robuste : puisqu'on ne peut pas identifier le vrai mécanisme, autant considérer un ensemble de mécanismes plausibles.

\subsubsection{Modélisation du mécanisme MNAR}

Pour simuler et analyser les mécanismes MNAR, on utilise typiquement un modèle de sélection :
\begin{equation}
    P(M_j = 1 | \mathbf{X}) = h_j(\mathbf{X}^{\text{obs}}, X_j; \boldsymbol{\alpha}_j)
\end{equation}
où $h_j$ est une fonction (souvent logistique) et $\boldsymbol{\alpha}_j$ sont des paramètres.

\begin{example}[Modèle logistique MNAR]
\begin{equation}
    P(M_j = 1 | X_j) = \sigma(\alpha_{j,0} + \alpha_{j,1} \cdot X_j) = \frac{1}{1 + e^{-(\alpha_{j,0} + \alpha_{j,1} X_j)}}
\end{equation}
où $\alpha_{j,1} > 0$ signifie que les grandes valeurs de $X_j$ sont plus souvent manquantes.
\end{example}

\subsubsection{Exemple numérique : impact du MNAR}

Pour illustrer concrètement l'impact du mécanisme MNAR, considérons un exemple simple avec $d = 1$ caractéristique.

\begin{example}[Biais d'imputation sous MNAR]
Soit $X \sim \mathcal{N}(100, 20^2)$ (par exemple, une glycémie en mg/dL). Supposons un mécanisme MNAR logistique :
\begin{equation}
    P(M = 1 | X) = \sigma\left( -2 + 0.03 \cdot X \right)
\end{equation}

Ce mécanisme implique :
\begin{itemize}
    \item Pour $X = 50$ (faible) : $P(M = 1) = \sigma(-0.5) \approx 0.38$
    \item Pour $X = 100$ (moyen) : $P(M = 1) = \sigma(1) \approx 0.73$
    \item Pour $X = 150$ (élevé) : $P(M = 1) = \sigma(2.5) \approx 0.92$
\end{itemize}

Les valeurs élevées sont beaucoup plus souvent manquantes (92\% vs 38\%).

\paragraph{Biais d'imputation.} Si l'on impute par la moyenne des valeurs observées, on calcule :
\begin{equation}
    \E[X | M = 0] = \E[X | X \text{ observé}] = \frac{\E[X \cdot \mathbf{1}_{M=0}]}{P(M=0)}
\end{equation}

Par calcul (ou simulation), on trouve $\E[X | M = 0] \approx 85$ au lieu de $\E[X] = 100$. L'imputation sous-estime systématiquement les valeurs manquantes de 15 unités !

\paragraph{Impact sur la classification.} Pour un seuil de diagnostic de diabète à glycémie $> 126$, cette sous-estimation conduit à :
\begin{itemize}
    \item Des faux négatifs : des patients diabétiques classés comme sains.
    \item Une sensibilité dégradée du classifieur.
\end{itemize}

\paragraph{Apport de la DRO.} En considérant un ensemble d'ambiguïté $\mathcal{P}_\epsilon$ avec $\epsilon > 0$, on ``couvre'' le cas où les valeurs manquantes sont plus élevées que ce que suggère l'imputation naïve. Le seuil de décision est ajusté vers le bas pour compenser le biais potentiel.
\end{example}

\begin{table}[H]
\centering
\caption{Impact du mécanisme MNAR sur l'imputation ($X \sim \mathcal{N}(100, 400)$)}
\label{tab:mnar_bias}
\begin{tabular}{lccc}
\toprule
Mécanisme & $\E[X | M = 0]$ & Biais & Impact sur diagnostic \\
\midrule
MCAR & 100.0 & 0 & Aucun \\
MAR (faible) & 97.5 & $-2.5$ & Léger \\
MNAR ($\beta = 0.03$) & 85.2 & $-14.8$ & Sévère \\
MNAR ($\beta = 0.05$) & 78.1 & $-21.9$ & Très sévère \\
\bottomrule
\end{tabular}
\end{table}

\subsection{DRO et données manquantes : le cadre unifié}
\label{subsec:dro_missing}

On montre maintenant comment la DRO offre un cadre naturel pour traiter l'incertitude sur le mécanisme de manquement.

\subsubsection{Sources d'incertitude}

Dans notre problème, l'incertitude porte sur :
\begin{enumerate}
    \item La distribution jointe $P(\mathbf{X}, Y)$ des données complètes.
    \item La distribution conditionnelle $P(\mathbf{X}^{\text{miss}} | \mathbf{X}^{\text{obs}})$ des valeurs manquantes.
    \item Le mécanisme de manquement $P(\mathbf{M} | \mathbf{X})$.
\end{enumerate}

La DRO traite ces incertitudes de façon unifiée en considérant un ensemble d'ambiguïté $\mathcal{P}_\epsilon$ autour d'une distribution de référence $P_0$.

\subsubsection{Distribution de référence $P_0$}

En pratique, $P_0$ est la distribution conditionnelle estimée des valeurs manquantes :
\begin{equation}
    P_0 = \hat{P}(\mathbf{X}^{\text{miss}} | \mathbf{X}^{\text{obs}})
\end{equation}

Cette distribution peut être estimée par :
\begin{itemize}
    \item Imputation gaussienne conditionnelle (hypothèse de normalité).
    \item MICE (Multiple Imputation by Chained Equations).
    \item Modèles génératifs (VAE, GAN).
\end{itemize}

L'ensemble d'ambiguïté $\mathcal{P}_\epsilon = \{P : W_p(P, P_0) \leq \epsilon\}$ capture alors l'incertitude sur cette estimation.

\subsubsection{Interprétation en termes de mécanisme}

Sous un mécanisme MNAR, la vraie distribution conditionnelle $P^*(\mathbf{X}^{\text{miss}} | \mathbf{X}^{\text{obs}})$ diffère de ce qu'on observerait sous MAR. La distance de Wasserstein $W_p(P^*, P_0)$ quantifie cet écart.

\begin{proposition}[Robustesse au shift de mécanisme]
Si le mécanisme réel est MNAR mais que $P_0$ est estimée sous l'hypothèse MAR, alors $W_p(P^*, P_0) > 0$. L'approche DRO avec $\epsilon \geq W_p(P^*, P_0)$ garantit que l'objectif optimisé majore le vrai risque sous le mécanisme MNAR.
\end{proposition}

\subsection{Formulation du problème à deux étapes}
\label{subsec:two_stage}

On formalise maintenant notre problème d'apprentissage avec acquisition de caractéristiques.

\subsubsection{Structure du problème}

Le problème se décompose en deux étapes :
\begin{enumerate}
    \item \textbf{Étape 1 (here-and-now)} : Observer $(\mathbf{x}^{\text{obs}}, \mathbf{m})$ et décider quelles caractéristiques acquérir ($\mathbf{z}$).
    \item \textbf{Étape 2 (recours)} : Après acquisition, observer les vraies valeurs pour $\{j : z_j = 1\}$, imputer le reste, et effectuer la prédiction.
\end{enumerate}

\subsubsection{Variables et paramètres}

\begin{itemize}
    \item $\mathbf{x} \in \R^d$ : Vecteur de caractéristiques complet (partiellement observé).
    \item $y \in \{0, 1\}$ : Variable cible à prédire.
    \item $\mathbf{m} \in \{0, 1\}^d$ : Masque de manquement observé.
    \item $\mathbf{z} \in \{0, 1\}^d$ : Décision d'acquisition ($z_j = 1$ si on acquiert $X_j$).
    \item $c_j \geq 0$ : Coût d'acquisition de la caractéristique $j$.
    \item $B > 0$ : Budget total disponible.
    \item $\boldsymbol{\xi} \in \R^{d_{\text{miss}}}$ : Vecteur aléatoire des valeurs manquantes.
    \item $f_\theta : \R^d \to [0, 1]$ : Modèle de prédiction (probabilité de $Y = 1$).
    \item $\ell : \{0,1\} \times [0,1] \to \R_+$ : Fonction de perte (log-loss).
\end{itemize}

\subsubsection{Vecteur reconstruit}

Après la décision d'acquisition $\mathbf{z}$ et la réalisation $\boldsymbol{\xi}$ des valeurs manquantes, le vecteur reconstruit est :
\begin{equation}
    \tilde{x}_j(\mathbf{z}, \boldsymbol{\xi}) = \begin{cases}
        x_j^{\text{obs}} & \text{si } m_j = 0 \text{ (observé gratuitement)} \\
        \xi_j & \text{si } m_j = 1 \text{ et } z_j = 1 \text{ (acquis)} \\
        \hat{x}_j & \text{si } m_j = 1 \text{ et } z_j = 0 \text{ (imputé)}
    \end{cases}
\end{equation}
où $\hat{x}_j = \E_{P_0}[\xi_j | \mathbf{x}^{\text{obs}}]$ est l'imputation par la moyenne conditionnelle.

\subsubsection{Formulation DRO complète}

Le problème d'acquisition DRO s'écrit :
\begin{equation}
\boxed{
\begin{aligned}
    \min_{\mathbf{z} \in \mathcal{Z}} \quad & R_{\text{DRO}}(\mathbf{z}) \\
    \text{où} \quad & R_{\text{DRO}}(\mathbf{z}) = \sup_{P \in \mathcal{P}_\epsilon} \E_P\left[ \ell\left(y, f_\theta(\tilde{\mathbf{x}}(\mathbf{z}, \boldsymbol{\xi}))\right) \right]
\end{aligned}
}
\label{eq:dro_acquisition}
\end{equation}

avec l'ensemble des décisions admissibles :
\begin{equation}
    \mathcal{Z} = \left\{ \mathbf{z} \in \{0, 1\}^d : \sum_{j=1}^d c_j z_j \leq B, \; z_j \leq m_j \; \forall j \right\}
\end{equation}

et l'ensemble d'ambiguïté :
\begin{equation}
    \mathcal{P}_\epsilon = \left\{ P : W_p(P, P_0) \leq \epsilon \right\}
\end{equation}

\subsubsection{Interprétation}

Le problème~\eqref{eq:dro_acquisition} cherche la stratégie d'acquisition $\mathbf{z}$ qui minimise le risque \textit{pire cas} parmi toutes les distributions $P$ à distance $\leq \epsilon$ de notre modèle de référence $P_0$.

\begin{itemize}
    \item Si $\epsilon = 0$ : On optimise l'espérance sous $P_0$ (approche non-robuste).
    \item Si $\epsilon \to \infty$ : On optimise pour le pire cas absolu (trop conservateur).
    \item Intermédiaire : Compromis entre adaptation aux données et robustesse.
\end{itemize}

\subsubsection{Propriétés structurelles}

\begin{proposition}[Monotonie]
Pour $\epsilon_1 \leq \epsilon_2$, on a $\mathcal{P}_{\epsilon_1} \subseteq \mathcal{P}_{\epsilon_2}$ et donc :
\begin{equation}
    R_{\text{DRO}}^{\epsilon_1}(\mathbf{z}) \leq R_{\text{DRO}}^{\epsilon_2}(\mathbf{z}) \quad \forall \mathbf{z}
\end{equation}
Le risque DRO est croissant en $\epsilon$.
\end{proposition}

\begin{proposition}[Convexité en $\mathbf{z}$ relaxé]
Si l'on relaxe $\mathbf{z} \in [0, 1]^d$ (décisions fractionnaires), l'objectif $R_{\text{DRO}}(\mathbf{z})$ n'est pas convexe en général. Cependant, pour des fonctions de perte convexes et des modèles linéaires, des approximations convexes existent.
\end{proposition}

\subsubsection{Cas particulier : acquisition indépendante}

Si les caractéristiques sont indépendantes conditionnellement aux observations, le problème se simplifie :

\begin{proposition}[Décomposition]
Sous l'hypothèse $P_0(\boldsymbol{\xi}) = \prod_j P_0(\xi_j | \mathbf{x}^{\text{obs}})$, le risque DRO peut se borner par :
\begin{equation}
    R_{\text{DRO}}(\mathbf{z}) \leq \sum_{j : m_j = 1} R_{\text{DRO}}^j(\mathbf{z})
\end{equation}
où $R_{\text{DRO}}^j$ est le risque associé à la $j$-ème caractéristique seule.
\end{proposition}

Cette borne suggère une heuristique gloutonne : acquérir les caractéristiques par ordre décroissant de ratio $R_{\text{DRO}}^j(z_j=0) - R_{\text{DRO}}^j(z_j=1)$ sur $c_j$.

\subsection{Complexité computationnelle}
\label{subsec:complexity}

On analyse maintenant la complexité du problème d'acquisition DRO.

\subsubsection{NP-difficulté du problème}

\begin{theorem}[Complexité du problème d'acquisition]
\label{thm:np_hard}
Le problème de décision associé à~\eqref{eq:dro_acquisition} --- ``Existe-t-il $\mathbf{z} \in \mathcal{Z}$ tel que $R_{\text{DRO}}(\mathbf{z}) \leq \tau$ pour un seuil $\tau$ donné ?'' --- est NP-difficile.
\end{theorem}

\begin{proof}[Esquisse de preuve]
On réduit le problème du sac à dos (Knapsack) à notre problème. Étant donné une instance du sac à dos avec objets de poids $w_j$ et valeurs $v_j$, et une capacité $W$, on construit une instance d'acquisition avec :
\begin{itemize}
    \item Coûts $c_j = w_j$
    \item Budget $B = W$
    \item Une fonction de perte construite telle que la réduction de risque par l'acquisition de la caractéristique $j$ soit exactement $v_j$
\end{itemize}

Cette construction est polynomiale, et résoudre le problème d'acquisition revient à résoudre l'instance du sac à dos. Puisque le sac à dos est NP-difficile, notre problème l'est aussi.
\end{proof}

\begin{remark}
Bien que NP-difficile en général, le problème devient tractable dans plusieurs cas :
\begin{enumerate}
    \item Si $d_{\text{miss}}$ est petit ($\leq 15$), l'énumération exacte de $2^{d_{\text{miss}}}$ configurations reste faisable.
    \item Si les coûts sont uniformes, le problème se réduit à une sélection de cardinalité.
    \item L'heuristique gloutonne fournit une approximation avec garantie.
\end{enumerate}
\end{remark}

\subsubsection{Approximation gloutonne}

\begin{theorem}[Garantie de l'approximation gloutonne]
\label{thm:greedy_approx}
Soit $\mathbf{z}^{\text{greedy}}$ la solution de l'algorithme glouton qui sélectionne itérativement la caractéristique maximisant le ratio $\Delta R_j / c_j$ où $\Delta R_j$ est la réduction de risque marginale. Si la fonction $R_{\text{DRO}}$ est sous-modulaire décroissante en $\mathbf{z}$, alors :
\begin{equation}
    R_{\text{DRO}}(\mathbf{z}^{\text{greedy}}) \leq \left(1 + \frac{1}{e-1}\right) \cdot R_{\text{DRO}}(\mathbf{z}^*)
\end{equation}
où $\mathbf{z}^*$ est la solution optimale.
\end{theorem}

\begin{proof}[Idée de preuve]
Ce résultat découle de l'analyse classique de l'algorithme glouton pour les fonctions sous-modulaires sous contrainte de budget (généralisation du problème de couverture d'ensemble). La preuve utilise le fait que la réduction de risque par l'acquisition de caractéristiques exhibe des rendements décroissants (acquérir une caractéristique quand beaucoup sont déjà connues apporte moins de valeur).
\end{proof}

\begin{remark}[Sous-modularité]
La fonction $R_{\text{DRO}}(\mathbf{z})$ n'est pas toujours sous-modulaire. Cependant, pour des modèles linéaires et des distributions gaussiennes, une version approchée de la sous-modularité tient, justifiant l'efficacité empirique de l'heuristique gloutonne.
\end{remark}

\subsection{Valeur de l'information}
\label{subsec:value_of_info}

On quantifie maintenant la valeur théorique de l'acquisition d'information.

\subsubsection{Définitions}

\begin{definition}[Valeur de l'information parfaite]
La valeur de l'information parfaite (VIP) pour le problème DRO est :
\begin{equation}
    \text{VIP} = R_{\text{DRO}}(\mathbf{0}) - R_{\text{DRO}}(\mathbf{1})
\end{equation}
où $\mathbf{0}$ correspond à aucune acquisition et $\mathbf{1}$ à l'acquisition complète (si le budget est illimité).
\end{definition}

\begin{definition}[Valeur marginale]
La valeur marginale de la caractéristique $j$ dans le contexte $\mathbf{z}$ est :
\begin{equation}
    V_j(\mathbf{z}) = R_{\text{DRO}}(\mathbf{z}) - R_{\text{DRO}}(\mathbf{z} + \mathbf{e}_j)
\end{equation}
où $\mathbf{e}_j$ est le $j$-ème vecteur canonique.
\end{definition}

\subsubsection{Bornes sur la valeur de l'information}

\begin{proposition}[Borne supérieure sur la VIP]
\label{prop:vip_bound}
Pour un modèle logistique avec paramètres $\theta$ et une distribution gaussienne $P_0$ des valeurs manquantes :
\begin{equation}
    \text{VIP} \leq \|\theta_{\text{miss}}\| \cdot \sqrt{\text{tr}(\Sigma_{\text{miss}|\text{obs}})}
\end{equation}
où $\theta_{\text{miss}}$ sont les composantes de $\theta$ correspondant aux caractéristiques manquantes, et $\Sigma_{\text{miss}|\text{obs}}$ est la matrice de covariance conditionnelle.
\end{proposition}

\begin{proof}
La variance de la prédiction due à l'incertitude sur les valeurs manquantes est :
\begin{equation}
    \Var_{P_0}[f_\theta(\tilde{x})] = \Var_{P_0}[\theta_{\text{miss}}^\top \boldsymbol{\xi}] = \theta_{\text{miss}}^\top \Sigma_{\text{miss}|\text{obs}} \theta_{\text{miss}}
\end{equation}

Par l'inégalité de Cauchy-Schwarz :
\begin{equation}
    \theta_{\text{miss}}^\top \Sigma_{\text{miss}|\text{obs}} \theta_{\text{miss}} \leq \|\theta_{\text{miss}}\|^2 \cdot \|\Sigma_{\text{miss}|\text{obs}}\|_2
\end{equation}

La réduction maximale de risque est proportionnelle à cette variance, d'où la borne.
\end{proof}

\begin{corollary}[Caractéristiques à haute valeur]
Les caractéristiques à haute valeur d'information sont celles qui :
\begin{enumerate}
    \item Ont un poids $|\theta_j|$ élevé dans le modèle (forte influence sur la prédiction).
    \item Ont une variance conditionnelle $\Var(\xi_j | \mathbf{x}^{\text{obs}})$ élevée (grande incertitude).
    \item Sont corrélées avec d'autres caractéristiques manquantes (effet de levier).
\end{enumerate}
\end{corollary}

\subsubsection{Effet de la robustesse sur la valeur}

\begin{proposition}[Valeur robuste vs non-robuste]
Soit $V_j^{\text{rob}}(\epsilon)$ la valeur marginale robuste (avec rayon $\epsilon$) et $V_j^{\text{NR}}$ la valeur non-robuste ($\epsilon = 0$). Alors :
\begin{equation}
    V_j^{\text{rob}}(\epsilon) \geq V_j^{\text{NR}} \quad \text{si } \Var(\xi_j) \text{ est élevée}
\end{equation}

Plus précisément, pour une distribution gaussienne :
\begin{equation}
    V_j^{\text{rob}}(\epsilon) - V_j^{\text{NR}} \approx \epsilon \cdot \theta_j^2 \cdot \left( \frac{\partial L}{\partial \Var(\xi_j)} \right)
\end{equation}
où $L$ est la constante de Lipschitz qui dépend de la variance.
\end{proposition}

\textbf{Interprétation.} La valeur robuste d'une caractéristique est plus grande que sa valeur non-robuste quand l'incertitude sur cette caractéristique est élevée. L'approche DRO ``valorise'' davantage la réduction d'incertitude que l'approche non-robuste.

\subsection{Convergence et consistance}
\label{subsec:convergence}

On établit des garanties asymptotiques pour l'approche SAA.

\subsubsection{Consistance de l'estimateur SAA}

\begin{theorem}[Consistance de SAA-DRO]
\label{thm:consistency}
Soit $\hat{R}_N(\mathbf{z})$ l'estimateur SAA avec $N$ scénarios et $R(\mathbf{z})$ le vrai objectif DRO. Sous des hypothèses de régularité (compacité de $\mathcal{Z}$, continuité de $\ell$) :
\begin{enumerate}
    \item \textbf{Convergence ponctuelle} : Pour tout $\mathbf{z}$ fixé,
    \begin{equation}
        \hat{R}_N(\mathbf{z}) \xrightarrow[N \to \infty]{p.s.} R(\mathbf{z})
    \end{equation}
    
    \item \textbf{Convergence uniforme} :
    \begin{equation}
        \sup_{\mathbf{z} \in \mathcal{Z}} \left| \hat{R}_N(\mathbf{z}) - R(\mathbf{z}) \right| \xrightarrow[N \to \infty]{p.s.} 0
    \end{equation}
    
    \item \textbf{Convergence de l'optimal} : Si $\hat{\mathbf{z}}_N = \argmin_{\mathbf{z} \in \mathcal{Z}} \hat{R}_N(\mathbf{z})$ et $\mathbf{z}^* = \argmin_{\mathbf{z} \in \mathcal{Z}} R(\mathbf{z})$, alors tout point d'accumulation de $\{\hat{\mathbf{z}}_N\}$ est un optimum global de $R$.
\end{enumerate}
\end{theorem}

\begin{proof}[Esquisse]
\begin{enumerate}
    \item Découle de la loi forte des grands nombres appliquée à $\frac{1}{N}\sum_k \ell(\tilde{x}^k)$.
    \item Résulte de la compacité de $\mathcal{Z}$ et de la continuité de $R$ en $\mathbf{z}$.
    \item Standard dans la théorie SAA : convergence épigraphique.
\end{enumerate}
\end{proof}

\subsubsection{Taux de convergence}

\begin{theorem}[Taux de convergence SAA]
\label{thm:rate}
Sous des hypothèses de régularité (sous-gaussianité des scénarios, bornes sur $\ell$), pour tout $\delta > 0$, avec probabilité au moins $1 - \delta$ :
\begin{equation}
    \left| \hat{R}_N(\mathbf{z}) - R(\mathbf{z}) \right| \leq C \sqrt{\frac{\log(1/\delta)}{N}}
\end{equation}
où $C$ dépend de la constante de Lipschitz $L$ et de la variance des scénarios.
\end{theorem}

\begin{corollary}[Choix de $N$ en pratique]
Pour garantir une erreur $\leq \varepsilon$ avec probabilité $\geq 1 - \delta$ :
\begin{equation}
    N \geq \frac{C^2 \log(1/\delta)}{\varepsilon^2}
\end{equation}

Pour $\varepsilon = 0.01$ et $\delta = 0.05$ avec $C = 1$, cela donne $N \geq 30\,000$. En pratique, $N = 500$ à $1000$ suffit souvent car les constantes sont plus favorables.
\end{corollary}

\subsection{Résumé des fondements théoriques}

Ce chapitre a établi les bases théoriques de notre approche :

\begin{enumerate}
    \item La \textbf{DRO} offre un cadre pour optimiser sous incertitude sur la distribution, en considérant un ensemble d'ambiguïté plutôt qu'une distribution unique.
    
    \item La \textbf{distance de Wasserstein} est une métrique sur les distributions qui tient compte de la géométrie de l'espace et possède des propriétés statistiques favorables (concentration, généralisation).
    
    \item Le \textbf{théorème de dualité} (Théorème~\ref{thm:dro_dual}) permet de reformuler le problème DRO-Wasserstein de façon tractable.
    
    \item Le mécanisme \textbf{MNAR} est non-identifiable (Théorème~\ref{thm:non_identifiability}), justifiant une approche robuste plutôt que la spécification d'un modèle de manquement particulier.
    
    \item Notre \textbf{formulation à deux étapes} intègre naturellement la décision d'acquisition et la robustesse distributionnelle dans un cadre unifié.
\end{enumerate}

%##############################################################################
%##############################################################################
\part{Méthodologie}
%##############################################################################
%##############################################################################

%==============================================================================
\section{Algorithmes et Implémentation}
\label{sec:methodologie}
%==============================================================================

Cette section constitue le cœur technique du projet. On y détaille les algorithmes développés pour résoudre le problème DRO à deux étapes, ainsi que les choix d'implémentation.

\subsection{Vue d'ensemble de l'approche}

La résolution du problème~\eqref{eq:probleme_principal} se décompose en plusieurs sous-problèmes :

\begin{enumerate}
    \item \textbf{Génération de scénarios} : Échantillonner $\boldsymbol{\xi}^1, \ldots, \boldsymbol{\xi}^N$ selon la distribution de référence $P_0$ des valeurs manquantes.
    \item \textbf{Évaluation de l'objectif DRO} : Pour un $\mathbf{z}$ fixé, calculer le risque pire cas via la reformulation duale.
    \item \textbf{Optimisation combinatoire} : Trouver le meilleur $\mathbf{z}$ parmi les configurations admissibles.
\end{enumerate}

La Figure~\ref{fig:pipeline} illustre ce pipeline.

% TODO: Ajouter figure du pipeline

\subsection{Génération de scénarios}
\label{subsec:generation_scenarios}

La qualité de l'approximation SAA dépend directement de la façon dont on génère les scénarios $\boldsymbol{\xi}^k$. On a besoin d'échantillonner selon $P_0$, la distribution conditionnelle des valeurs manquantes sachant les valeurs observées.

\subsubsection{Imputation conditionnelle gaussienne}

L'approche la plus simple suppose que $\mathbf{x}$ suit une loi gaussienne multivariée :
\begin{equation}
    \mathbf{x} \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma})
\end{equation}

Dans ce cas, la loi conditionnelle $\mathbf{x}^{\text{miss}} | \mathbf{x}^{\text{obs}}$ est elle-même gaussienne :
\begin{equation}
    \mathbf{x}^{\text{miss}} | \mathbf{x}^{\text{obs}} \sim \mathcal{N}(\boldsymbol{\mu}_{\text{cond}}, \boldsymbol{\Sigma}_{\text{cond}})
\end{equation}
avec :
\begin{align}
    \boldsymbol{\mu}_{\text{cond}} &= \boldsymbol{\mu}_{\text{miss}} + \boldsymbol{\Sigma}_{\text{miss,obs}} \boldsymbol{\Sigma}_{\text{obs,obs}}^{-1} (\mathbf{x}^{\text{obs}} - \boldsymbol{\mu}_{\text{obs}}) \label{eq:mu_cond}\\
    \boldsymbol{\Sigma}_{\text{cond}} &= \boldsymbol{\Sigma}_{\text{miss,miss}} - \boldsymbol{\Sigma}_{\text{miss,obs}} \boldsymbol{\Sigma}_{\text{obs,obs}}^{-1} \boldsymbol{\Sigma}_{\text{obs,miss}} \label{eq:sigma_cond}
\end{align}

où les indices désignent les sous-matrices correspondantes de $\boldsymbol{\Sigma}$.

\begin{algorithm}[H]
\caption{Génération de scénarios par imputation gaussienne}
\label{alg:gaussian_imputation}
\begin{algorithmic}[1]
\REQUIRE Données d'entraînement $\mathcal{D}$, observation $(\mathbf{x}^{\text{obs}}, \mathbf{m})$, nombre de scénarios $N$
\ENSURE Scénarios $\{\boldsymbol{\xi}^1, \ldots, \boldsymbol{\xi}^N\}$

\STATE Estimer $\hat{\boldsymbol{\mu}}, \hat{\boldsymbol{\Sigma}}$ à partir de $\mathcal{D}$ (sur données complètes ou via EM)
\STATE Identifier $\mathcal{I}_{\text{obs}} = \{j : m_j = 0\}$ et $\mathcal{I}_{\text{miss}} = \{j : m_j = 1\}$
\STATE Extraire les sous-matrices $\hat{\boldsymbol{\Sigma}}_{\text{obs,obs}}$, $\hat{\boldsymbol{\Sigma}}_{\text{miss,obs}}$, $\hat{\boldsymbol{\Sigma}}_{\text{miss,miss}}$
\STATE Calculer $\boldsymbol{\mu}_{\text{cond}}$ selon~\eqref{eq:mu_cond}
\STATE Calculer $\boldsymbol{\Sigma}_{\text{cond}}$ selon~\eqref{eq:sigma_cond}
\STATE Factoriser $\boldsymbol{\Sigma}_{\text{cond}} = \mathbf{L}\mathbf{L}^\top$ (Cholesky)

\FOR{$k = 1$ \textbf{à} $N$}
    \STATE Tirer $\mathbf{u}^k \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$
    \STATE $\boldsymbol{\xi}^k \gets \boldsymbol{\mu}_{\text{cond}} + \mathbf{L} \mathbf{u}^k$
\ENDFOR

\RETURN $\{\boldsymbol{\xi}^1, \ldots, \boldsymbol{\xi}^N\}$
\end{algorithmic}
\end{algorithm}

\subsubsection{Imputation par MICE}

Pour des distributions non-gaussiennes, on utilise MICE (\textit{Multiple Imputation by Chained Equations}). L'idée est de modéliser chaque variable manquante conditionnellement aux autres via une régression.

\begin{algorithm}[H]
\caption{Génération de scénarios par MICE}
\label{alg:mice}
\begin{algorithmic}[1]
\REQUIRE Données $\mathcal{D}$ avec valeurs manquantes, nombre d'itérations $T$, nombre de scénarios $N$
\ENSURE Scénarios $\{\boldsymbol{\xi}^1, \ldots, \boldsymbol{\xi}^N\}$

\STATE Initialiser les valeurs manquantes par la moyenne marginale
\FOR{$t = 1$ \textbf{à} $T$}
    \FOR{chaque variable $j$ avec des valeurs manquantes}
        \STATE Ajuster un modèle $\hat{f}_j$ : $X_j \sim X_{-j}$ sur les données où $X_j$ est observé
        \STATE Pour les données où $X_j$ est manquant, tirer $X_j$ selon $\hat{f}_j(X_{-j}) + \varepsilon$
    \ENDFOR
\ENDFOR

\FOR{$k = 1$ \textbf{à} $N$}
    \STATE Répéter le processus ci-dessus avec des tirages aléatoires différents
    \STATE Stocker $\boldsymbol{\xi}^k$ = valeurs imputées pour l'observation courante
\ENDFOR

\RETURN $\{\boldsymbol{\xi}^1, \ldots, \boldsymbol{\xi}^N\}$
\end{algorithmic}
\end{algorithm}

\subsubsection{Réduction de variance par quasi-Monte Carlo}

Pour améliorer la convergence de SAA, on peut remplacer les tirages pseudo-aléatoires par des séquences à faible discrépance (Sobol, Halton). Ces séquences couvrent l'espace de façon plus uniforme, réduisant l'erreur d'approximation.

Concrètement, au lieu de tirer $\mathbf{u}^k \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$, on :
\begin{enumerate}
    \item Génère un point $\mathbf{v}^k \in [0,1]^{d_{\text{miss}}}$ de la séquence de Sobol
    \item Transforme via la fonction quantile : $u_j^k = \Phi^{-1}(v_j^k)$
\end{enumerate}

\subsection{Évaluation de l'objectif DRO}
\label{subsec:evaluation_dro}

Pour un vecteur de décision $\mathbf{z}$ fixé, on doit calculer :
\begin{equation}
    R_{\text{DRO}}(\mathbf{z}) = \max_{P \in \mathcal{P}_\epsilon} \E_P\left[\ell(y, f_\theta(\tilde{\mathbf{x}}(\mathbf{z}, \boldsymbol{\xi})))\right]
\end{equation}

En utilisant la reformulation duale~\eqref{eq:dro_dual} et l'approximation SAA :
\begin{equation}
    \hat{R}_{\text{DRO}}^N(\mathbf{z}) = \inf_{\lambda \geq 0} \left\{ \lambda \epsilon^p + \frac{1}{N} \sum_{k=1}^{N} \phi_\lambda(\boldsymbol{\xi}^k, \mathbf{z}) \right\}
\label{eq:saa_dro}
\end{equation}
où :
\begin{equation}
    \phi_\lambda(\boldsymbol{\xi}, \mathbf{z}) = \sup_{\boldsymbol{\xi}'} \left\{ \ell(y, f_\theta(\tilde{\mathbf{x}}(\mathbf{z}, \boldsymbol{\xi}'))) - \lambda \|\boldsymbol{\xi}' - \boldsymbol{\xi}\|^p \right\}
\label{eq:phi_lambda}
\end{equation}

\subsubsection{Calcul du supremum interne}

Le terme $\phi_\lambda$ est le plus délicat à calculer. Sa forme dépend de la fonction de perte $\ell$ et du modèle $f_\theta$.

\paragraph{Cas de la régression logistique avec log-loss.}

Pour la classification binaire avec :
\begin{equation}
    f_\theta(\tilde{\mathbf{x}}) = \sigma(\theta^\top \tilde{\mathbf{x}}) = \frac{1}{1 + e^{-\theta^\top \tilde{\mathbf{x}}}}
\end{equation}
et la log-loss :
\begin{equation}
    \ell(y, \hat{y}) = -y \log(\hat{y}) - (1-y)\log(1-\hat{y})
\end{equation}

La perte est convexe en $\tilde{\mathbf{x}}$ (pour $y$ fixé) mais pas lipschitzienne globalement. On peut cependant la tronquer sur un domaine borné $\mathcal{X}$ et obtenir une constante de Lipschitz $L$.

\begin{proposition}[Constante de Lipschitz de la log-loss]
Sur un domaine $\|\tilde{\mathbf{x}}\| \leq R$, la log-loss composée avec la régression logistique est lipschitzienne de constante :
\begin{equation}
    L = \|\theta\| \cdot \max\left(\frac{1}{\sigma_{\min}}, \frac{1}{1-\sigma_{\max}}\right)
\end{equation}
où $\sigma_{\min}, \sigma_{\max}$ sont les bornes de $\sigma(\theta^\top \tilde{\mathbf{x}})$ sur le domaine.
\end{proposition}

Lorsque $\lambda \geq L$, le supremum dans~\eqref{eq:phi_lambda} est atteint en $\boldsymbol{\xi}' = \boldsymbol{\xi}$ et on a simplement :
\begin{equation}
    \phi_\lambda(\boldsymbol{\xi}, \mathbf{z}) = \ell(y, f_\theta(\tilde{\mathbf{x}}(\mathbf{z}, \boldsymbol{\xi})))
\end{equation}

Cela simplifie considérablement le calcul : il suffit d'optimiser sur $\lambda \geq L$.

\subsubsection{Optimisation sur $\lambda$}

L'objectif~\eqref{eq:saa_dro} est convexe en $\lambda$ (somme d'une fonction affine et de supremums de fonctions affines). On peut donc utiliser une recherche par bissection ou la méthode de Newton.

\begin{algorithm}[H]
\caption{Évaluation de l'objectif DRO pour un $\mathbf{z}$ fixé}
\label{alg:eval_dro}
\begin{algorithmic}[1]
\REQUIRE Scénarios $\{\boldsymbol{\xi}^k\}_{k=1}^N$, décision $\mathbf{z}$, rayon $\epsilon$, modèle $f_\theta$, constante $L$
\ENSURE Estimation $\hat{R}_{\text{DRO}}^N(\mathbf{z})$

\STATE $\lambda_{\min} \gets L$ \COMMENT{Borne inférieure}
\STATE $\lambda_{\max} \gets L + \frac{1}{\epsilon}$ \COMMENT{Borne supérieure heuristique}

\WHILE{$\lambda_{\max} - \lambda_{\min} > \text{tol}$}
    \STATE $\lambda \gets (\lambda_{\min} + \lambda_{\max}) / 2$
    \STATE $g(\lambda) \gets \lambda \epsilon^p + \frac{1}{N} \sum_{k=1}^{N} \ell(y, f_\theta(\tilde{\mathbf{x}}(\mathbf{z}, \boldsymbol{\xi}^k)))$
    \STATE Calculer le sous-gradient $\partial g / \partial \lambda$
    \STATE Mettre à jour $[\lambda_{\min}, \lambda_{\max}]$ selon le signe du sous-gradient
\ENDWHILE

\RETURN $g(\lambda)$
\end{algorithmic}
\end{algorithm}

\begin{remark}
En pratique, pour $\lambda \geq L$, l'objectif devient $\lambda \epsilon^p + \bar{\ell}$ où $\bar{\ell}$ est la perte moyenne. L'optimum est atteint en $\lambda^* = L$, ce qui donne :
\begin{equation}
    \hat{R}_{\text{DRO}}^N(\mathbf{z}) = L \epsilon^p + \frac{1}{N} \sum_{k=1}^{N} \ell(y, f_\theta(\tilde{\mathbf{x}}(\mathbf{z}, \boldsymbol{\xi}^k)))
\end{equation}
La robustesse se traduit par un terme additif $L\epsilon^p$ qui pénalise les modèles à grande constante de Lipschitz.
\end{remark}

\subsection{Optimisation combinatoire sur $\mathbf{z}$}
\label{subsec:optimisation_z}

Il reste à trouver le meilleur $\mathbf{z}$ parmi l'ensemble des configurations admissibles :
\begin{equation}
    \mathcal{Z} = \left\{ \mathbf{z} \in \{0,1\}^d : \sum_j c_j z_j \leq B, \; z_j \leq m_j \; \forall j \right\}
\end{equation}

\subsubsection{Énumération pour petites instances}

Si le nombre de caractéristiques manquantes $d_{\text{miss}} = |\{j : m_j = 1\}|$ est petit (disons $\leq 15$), on peut énumérer toutes les configurations admissibles.

\begin{algorithm}[H]
\caption{Résolution par énumération}
\label{alg:enumeration}
\begin{algorithmic}[1]
\REQUIRE Ensemble $\mathcal{Z}$, fonction d'évaluation $\hat{R}_{\text{DRO}}^N(\cdot)$
\ENSURE Solution optimale $\mathbf{z}^*$

\STATE $R^* \gets +\infty$
\STATE $\mathbf{z}^* \gets \mathbf{0}$

\FOR{chaque $\mathbf{z} \in \mathcal{Z}$}
    \STATE $R \gets \hat{R}_{\text{DRO}}^N(\mathbf{z})$
    \IF{$R < R^*$}
        \STATE $R^* \gets R$
        \STATE $\mathbf{z}^* \gets \mathbf{z}$
    \ENDIF
\ENDFOR

\RETURN $\mathbf{z}^*$
\end{algorithmic}
\end{algorithm}

\subsubsection{Heuristique gloutonne}

Pour des instances plus grandes, on utilise une heuristique gloutonne basée sur le ratio valeur/coût.

\begin{definition}[Valeur marginale robuste]
La valeur marginale robuste de la caractéristique $j$ étant donné $\mathbf{z}$ est :
\begin{equation}
    V_j(\mathbf{z}) = \hat{R}_{\text{DRO}}^N(\mathbf{z}) - \hat{R}_{\text{DRO}}^N(\mathbf{z} + \mathbf{e}_j)
\end{equation}
où $\mathbf{e}_j$ est le $j$-ème vecteur canonique.
\end{definition}

\begin{algorithm}[H]
\caption{Heuristique gloutonne}
\label{alg:greedy}
\begin{algorithmic}[1]
\REQUIRE Caractéristiques manquantes $\mathcal{I}_{\text{miss}}$, coûts $\{c_j\}$, budget $B$
\ENSURE Solution $\mathbf{z}$

\STATE $\mathbf{z} \gets \mathbf{0}$
\STATE $B_{\text{restant}} \gets B$

\WHILE{$B_{\text{restant}} > 0$}
    \STATE \COMMENT{Calculer les ratios valeur/coût}
    \FOR{$j \in \mathcal{I}_{\text{miss}}$ tel que $z_j = 0$ et $c_j \leq B_{\text{restant}}$}
        \STATE $\rho_j \gets V_j(\mathbf{z}) / c_j$
    \ENDFOR
    
    \IF{aucun $j$ admissible}
        \STATE \textbf{break}
    \ENDIF
    
    \STATE $j^* \gets \argmax_j \rho_j$
    
    \IF{$V_{j^*}(\mathbf{z}) \leq 0$}
        \STATE \textbf{break} \COMMENT{Plus d'amélioration possible}
    \ENDIF
    
    \STATE $z_{j^*} \gets 1$
    \STATE $B_{\text{restant}} \gets B_{\text{restant}} - c_{j^*}$
\ENDWHILE

\RETURN $\mathbf{z}$
\end{algorithmic}
\end{algorithm}

\subsection{Algorithme complet SAA-DRO}
\label{subsec:algo_complet}

On peut maintenant assembler tous les morceaux en un algorithme complet.

\begin{algorithm}[H]
\caption{SAA-DRO pour l'acquisition de caractéristiques}
\label{alg:saa_dro_complet}
\begin{algorithmic}[1]
\REQUIRE Données d'entraînement $\mathcal{D}$, nouvelle observation $(\mathbf{x}^{\text{obs}}, \mathbf{m}, y)$
\REQUIRE Coûts $\{c_j\}$, budget $B$, rayon $\epsilon$, nombre de scénarios $N$
\ENSURE Décision d'acquisition $\mathbf{z}^*$, prédiction $\hat{y}$

\STATE \COMMENT{Phase 1 : Préparation}
\STATE Entraîner le modèle $f_\theta$ sur $\mathcal{D}$
\STATE Estimer les paramètres de $P_0$ (imputation)

\STATE \COMMENT{Phase 2 : Génération de scénarios}
\STATE $\{\boldsymbol{\xi}^1, \ldots, \boldsymbol{\xi}^N\} \gets$ \textsc{GénérerScénarios}$(\mathcal{D}, \mathbf{x}^{\text{obs}}, \mathbf{m}, N)$

\STATE \COMMENT{Phase 3 : Optimisation}
\IF{$d_{\text{miss}} \leq 15$}
    \STATE $\mathbf{z}^* \gets$ \textsc{Énumération}$(\mathcal{Z}, \{\boldsymbol{\xi}^k\}, \epsilon)$
\ELSE
    \STATE $\mathbf{z}^* \gets$ \textsc{Glouton}$(\mathcal{I}_{\text{miss}}, \{c_j\}, B, \{\boldsymbol{\xi}^k\}, \epsilon)$
\ENDIF

\STATE \COMMENT{Phase 4 : Prédiction}
\STATE Acquérir les caractéristiques $\{j : z_j^* = 1\}$ (révéler les vraies valeurs)
\STATE Imputer les caractéristiques restantes : $\hat{x}_j = \E[\xi_j]$ pour $j : m_j = 1, z_j^* = 0$
\STATE Construire $\tilde{\mathbf{x}}^*$
\STATE $\hat{y} \gets f_\theta(\tilde{\mathbf{x}}^*)$

\RETURN $\mathbf{z}^*, \hat{y}$
\end{algorithmic}
\end{algorithm}

\subsection{Calibrage du rayon $\epsilon$}
\label{subsec:calibrage_epsilon}

Le choix de $\epsilon$ est crucial. On propose deux approches.

\subsubsection{Approche théorique}

Sous certaines hypothèses (distribution sous-gaussienne), la vraie distribution $P^*$ satisfait $W_p(P^*, \hat{P}_N) \leq \epsilon_N$ avec haute probabilité si :
\begin{equation}
    \epsilon_N = c \cdot \begin{cases}
        N^{-1/2} & \text{si } d_{\text{miss}} < 2p\\
        N^{-1/d_{\text{miss}}} \cdot (\log N)^{1/p} & \text{si } d_{\text{miss}} > 2p
    \end{cases}
\end{equation}

En pratique, la constante $c$ dépend de la distribution et doit être estimée.

\subsubsection{Validation croisée}

On sélectionne $\epsilon$ par validation croisée sur un critère de robustesse :

\begin{algorithm}[H]
\caption{Calibrage de $\epsilon$ par validation croisée}
\label{alg:cv_epsilon}
\begin{algorithmic}[1]
\REQUIRE Données $\mathcal{D}$, grille $\{\epsilon_1, \ldots, \epsilon_G\}$, nombre de folds $K$
\ENSURE Rayon optimal $\epsilon^*$

\FOR{$g = 1$ \textbf{à} $G$}
    \FOR{$k = 1$ \textbf{à} $K$}
        \STATE Séparer $\mathcal{D}$ en $\mathcal{D}_{\text{train}}^{(k)}$ et $\mathcal{D}_{\text{val}}^{(k)}$
        \STATE Entraîner SAA-DRO avec $\epsilon_g$ sur $\mathcal{D}_{\text{train}}^{(k)}$
        \STATE Évaluer sur $\mathcal{D}_{\text{val}}^{(k)}$ sous plusieurs mécanismes de manquement
        \STATE $\text{score}_{g,k} \gets$ pire performance parmi les mécanismes
    \ENDFOR
    \STATE $\bar{\text{score}}_g \gets \frac{1}{K} \sum_k \text{score}_{g,k}$
\ENDFOR

\RETURN $\epsilon^* = \epsilon_{\argmin_g \bar{\text{score}}_g}$
\end{algorithmic}
\end{algorithm}

\subsection{Analyse de complexité}
\label{subsec:complexite}

\begin{proposition}[Complexité de l'algorithme SAA-DRO]
Soit $n$ le nombre d'observations d'entraînement, $d$ la dimension, $d_{\text{miss}}$ le nombre de caractéristiques manquantes, et $N$ le nombre de scénarios. La complexité de l'Algorithme~\ref{alg:saa_dro_complet} est :
\begin{itemize}
    \item Génération de scénarios : $O(d^3 + N \cdot d_{\text{miss}})$ (inversion de matrice + tirages)
    \item Évaluation DRO pour un $\mathbf{z}$ : $O(N \cdot d)$ (évaluation du modèle sur $N$ scénarios)
    \item Optimisation sur $\mathbf{z}$ :
    \begin{itemize}
        \item Énumération : $O(2^{d_{\text{miss}}} \cdot N \cdot d)$
        \item Glouton : $O(d_{\text{miss}}^2 \cdot N \cdot d)$
    \end{itemize}
\end{itemize}
\end{proposition}

Pour $d_{\text{miss}} = 10$, $N = 1000$, $d = 20$, l'énumération nécessite environ $2^{10} \times 1000 \times 20 \approx 2 \times 10^7$ opérations, ce qui reste tractable sur un ordinateur moderne.

\subsection{Implémentation}

Le code est implémenté en Julia pour sa performance numérique. Les principaux modules sont :

\begin{itemize}
    \item \texttt{scenario\_generation.jl} : Imputation gaussienne et MICE
    \item \texttt{dro\_objective.jl} : Calcul de l'objectif DRO
    \item \texttt{acquisition\_solver.jl} : Énumération et heuristique gloutonne
    \item \texttt{saa\_dro.jl} : Algorithme principal
\end{itemize}

Le code complet est fourni en annexe et disponible dans le dépôt accompagnant ce rapport.

%##############################################################################
%##############################################################################
\part{Expériences et Résultats}
%##############################################################################
%##############################################################################

%==============================================================================
\section{Cadre Expérimental}
\label{sec:cadre_experimental}
%==============================================================================

Cette section décrit en détail le protocole expérimental utilisé pour évaluer notre approche DRO. On présente les jeux de données, la simulation des mécanismes de manquement, les métriques d'évaluation, et les méthodes de comparaison.

\subsection{Jeux de données}
\label{subsec:datasets}

On utilise deux jeux de données classiques en diagnostic médical, disponibles sur UCI Machine Learning Repository. Ces datasets ont été choisis car ils représentent des situations réalistes où l'acquisition de caractéristiques a un coût (examens médicaux) et où le mécanisme de manquement peut être MNAR (le médecin prescrit un test s'il suspecte quelque chose).

\subsubsection{Pima Indians Diabetes}

Ce dataset, collecté par le National Institute of Diabetes and Digestive and Kidney Diseases, contient 768 observations de femmes d'origine Pima (population amérindienne à forte prévalence de diabète), âgées d'au moins 21 ans. L'objectif est de prédire si une patiente est diabétique ($y = 1$) ou non ($y = 0$) à partir de 8 caractéristiques médicales.

\begin{table}[H]
\centering
\caption{Caractéristiques du dataset Pima Indians Diabetes}
\label{tab:pima_features}
\begin{tabular}{clccc}
\toprule
$j$ & Variable & Moyenne $\pm$ Écart-type & Coût $c_j$ & Type d'examen \\
\midrule
1 & Pregnancies & $3.85 \pm 3.37$ & 0 & Anamnèse \\
2 & Glucose & $120.89 \pm 31.97$ & 10 & Test sanguin \\
3 & BloodPressure & $69.11 \pm 19.36$ & 5 & Examen clinique \\
4 & SkinThickness & $20.54 \pm 15.95$ & 8 & Mesure anthropométrique \\
5 & Insulin & $79.80 \pm 115.24$ & 15 & Test sanguin spécialisé \\
6 & BMI & $31.99 \pm 7.88$ & 2 & Calcul (poids/taille) \\
7 & DiabetesPedigree & $0.47 \pm 0.33$ & 0 & Questionnaire \\
8 & Age & $33.24 \pm 11.76$ & 0 & Anamnèse \\
\midrule
\multicolumn{2}{l}{Prévalence diabète} & \multicolumn{3}{c}{34.9\% ($y = 1$)} \\
\bottomrule
\end{tabular}
\end{table}

Les coûts d'acquisition sont simulés de façon réaliste selon le type d'examen :
\begin{itemize}
    \item \textbf{Coût 0} : Informations obtenues par questionnaire ou observation directe (âge, nombre de grossesses, historique familial).
    \item \textbf{Coût 2} : Calculs simples à partir de mesures de base (IMC = poids/taille²).
    \item \textbf{Coût 5-8} : Examens cliniques nécessitant un équipement standard (tensiomètre, pied à coulisse).
    \item \textbf{Coût 10-15} : Analyses sanguines nécessitant un prélèvement et un laboratoire.
\end{itemize}

\begin{remark}
Le dataset Pima contient des valeurs aberrantes codées comme 0 (par exemple, Glucose = 0 ou BloodPressure = 0, ce qui est physiologiquement impossible). Dans nos expériences, ces valeurs sont traitées comme manquantes dans les données d'origine, ce qui renforce le réalisme du scénario.
\end{remark}

\subsubsection{Heart Disease Cleveland}

Ce dataset, collecté à la Cleveland Clinic Foundation, contient 303 observations avec 13 caractéristiques et une variable cible binaire indiquant la présence de maladie cardiaque. C'est un problème plus complexe avec davantage de caractéristiques potentiellement acquérables.

\begin{table}[H]
\centering
\caption{Caractéristiques du dataset Heart Disease Cleveland}
\label{tab:heart_features}
\begin{tabular}{clccc}
\toprule
$j$ & Variable & Description & Coût $c_j$ & Type \\
\midrule
1 & Age & Âge en années & 0 & Anamnèse \\
2 & Sex & Sexe (1=H, 0=F) & 0 & Observation \\
3 & ChestPain & Type de douleur thoracique (0-3) & 5 & Examen clinique \\
4 & RestingBP & Pression au repos (mm Hg) & 5 & Examen clinique \\
5 & Cholesterol & Cholestérol sérique (mg/dl) & 12 & Test sanguin \\
6 & FastingBS & Glycémie à jeun $> 120$ (0/1) & 8 & Test sanguin \\
7 & RestingECG & Résultats ECG au repos (0-2) & 15 & ECG \\
8 & MaxHR & Fréquence cardiaque max & 10 & Test d'effort \\
9 & ExerciseAngina & Angine induite par exercice & 5 & Test d'effort \\
10 & Oldpeak & Dépression ST induite & 10 & ECG d'effort \\
11 & ST\_Slope & Pente du segment ST & 15 & ECG d'effort \\
12 & NumVessels & Nb vaisseaux colorés (0-3) & 25 & Fluoroscopie \\
13 & Thal & Thalassémie (3=normal, 6=fixe, 7=réversible) & 20 & Scintigraphie \\
\midrule
\multicolumn{2}{l}{Prévalence maladie} & \multicolumn{3}{c}{45.5\% ($y = 1$)} \\
\bottomrule
\end{tabular}
\end{table}

Ce dataset est particulièrement intéressant car :
\begin{enumerate}
    \item Les coûts varient fortement (0 à 25), permettant d'observer des stratégies d'acquisition non triviales.
    \item Certains examens sont corrélés (ECG repos et effort), ce qui rend la valeur de l'information dépendante du contexte.
    \item Les examens les plus informatifs (fluoroscopie, scintigraphie) sont aussi les plus coûteux, créant un vrai compromis.
\end{enumerate}

\subsubsection{Prétraitement des données}

Pour les deux datasets, on applique le prétraitement suivant :
\begin{enumerate}
    \item \textbf{Gestion des valeurs aberrantes} : Les valeurs physiologiquement impossibles (ex: Glucose = 0) sont marquées comme manquantes.
    \item \textbf{Normalisation} : Chaque caractéristique est centrée-réduite sur l'ensemble d'entraînement :
    \begin{equation}
        \tilde{x}_j = \frac{x_j - \hat{\mu}_j}{\hat{\sigma}_j}
    \end{equation}
    Les paramètres $\hat{\mu}_j, \hat{\sigma}_j$ sont estimés sur le train et appliqués au test.
    \item \textbf{Séparation train/test} : On utilise 80\% des données pour l'entraînement et 20\% pour le test, avec stratification sur la classe.
\end{enumerate}

\subsection{Simulation des mécanismes de manquement}
\label{subsec:missing_mechanisms}

Pour évaluer la robustesse de notre approche, on simule différents mécanismes de manquement sur les données de test. On contrôle le taux de manquement global $p_{\text{miss}}$ et on protège certaines caractéristiques (celles de coût 0) qui sont toujours observées.

\subsubsection{MCAR : Missing Completely At Random}

Le mécanisme le plus simple : chaque valeur est manquante indépendamment avec probabilité $p_{\text{miss}}$.

\begin{equation}
    P(M_j = 1) = p_{\text{miss}}, \quad \forall j \in \mathcal{J}_{\text{acquirable}}
\end{equation}

où $\mathcal{J}_{\text{acquirable}} = \{j : c_j > 0\}$ est l'ensemble des caractéristiques payantes.

Ce mécanisme sert de référence car l'imputation classique est théoriquement optimale sous MCAR.

\subsubsection{MAR : Missing At Random}

Le manquement dépend d'une variable toujours observée. On utilise l'âge comme variable conditionnante :

\begin{equation}
    P(M_j = 1 | \text{Age}) = \sigma\left(\alpha + \beta \cdot \frac{\text{Age} - \bar{\text{Age}}}{\sigma_{\text{Age}}}\right)
\end{equation}

où $\sigma(z) = 1/(1 + e^{-z})$ est la fonction sigmoïde. Les paramètres $\alpha$ et $\beta$ sont calibrés pour obtenir le taux de manquement cible $p_{\text{miss}}$.

\textbf{Interprétation clinique} : Les patients âgés ont plus d'examens manquants (par exemple, ils refusent certains tests invasifs).

\subsubsection{MNAR : Missing Not At Random}

C'est le cas le plus réaliste et le plus problématique. La probabilité de manquement dépend de la valeur elle-même :

\begin{equation}
    P(M_j = 1 | X_j) = \sigma\left(\alpha_j + \beta_j \cdot \frac{X_j - \bar{X}_j}{\sigma_{X_j}}\right)
\end{equation}

On considère deux variantes selon le signe de $\beta_j$ :

\paragraph{MNAR+ ($\beta_j > 0$)} Les valeurs élevées sont plus souvent manquantes.

\textbf{Interprétation clinique} : Le médecin prescrit un test de glycémie quand il suspecte un diabète (glycémie potentiellement élevée). Si le patient a une glycémie normale, le test n'est pas prescrit $\Rightarrow$ les valeurs normales sont observées, les valeurs élevées sont manquantes.

\textit{Attention} : Cette situation semble contre-intuitive mais elle modélise le cas où les données d'entraînement viennent de patients ``tout-venant'' alors que les données de test viennent de patients ``ciblés''.

\paragraph{MNAR-- ($\beta_j < 0$)} Les valeurs basses sont plus souvent manquantes.

\textbf{Interprétation clinique} : Le médecin prescrit un test quand il suspecte un problème. Si le résultat est normal (bas), le test n'est pas renouvelé lors des visites suivantes. Les valeurs anormales (élevées) sont plus souvent mesurées.

\subsubsection{MNAR avec effet de seuil}

Une variante plus réaliste du MNAR utilise un effet de seuil plutôt qu'une relation linéaire :

\begin{equation}
    P(M_j = 1 | X_j) = \begin{cases}
        p_{\text{low}} & \text{si } X_j < Q_{0.7}(X_j) \\
        p_{\text{high}} & \text{si } X_j \geq Q_{0.7}(X_j)
    \end{cases}
\end{equation}

où $Q_{0.7}$ est le 70ème percentile et $p_{\text{high}} \gg p_{\text{low}}$.

\textbf{Interprétation} : Le médecin prescrit un test seulement si un score de risque dépasse un seuil clinique.

\subsubsection{Paramétrage des mécanismes}

Pour toutes les expériences, on utilise les paramètres suivants sauf mention contraire :

\begin{table}[H]
\centering
\caption{Paramètres des mécanismes de manquement}
\label{tab:missing_params}
\begin{tabular}{lcc}
\toprule
Mécanisme & Paramètres & Taux cible \\
\midrule
MCAR & $p_{\text{miss}} = 0.3$ & 30\% \\
MAR & $\alpha = -1.5$, $\beta = 1.0$ & $\approx$ 30\% \\
MNAR+ & $\alpha = -1.5$, $\beta = 0.8$ & $\approx$ 30\% \\
MNAR-- & $\alpha = -1.5$, $\beta = -0.8$ & $\approx$ 30\% \\
MNAR-seuil & $p_{\text{low}} = 0.1$, $p_{\text{high}} = 0.5$ & $\approx$ 22\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Métriques d'évaluation}
\label{subsec:metrics}

On évalue les méthodes selon plusieurs axes complémentaires.

\subsubsection{Performance prédictive}

\paragraph{Accuracy} Le taux de classification correcte :
\begin{equation}
    \text{Acc} = \frac{1}{n_{\text{test}}} \sum_{i=1}^{n_{\text{test}}} \mathbf{1}[\hat{y}_i = y_i]
\end{equation}
où $\hat{y}_i = \mathbf{1}[\hat{p}_i > 0.5]$.

\paragraph{Log-loss (entropie croisée)} La perte logarithmique moyenne, qui pénalise les prédictions confiantes mais fausses :
\begin{equation}
    \mathcal{L} = -\frac{1}{n_{\text{test}}} \sum_{i=1}^{n_{\text{test}}} \left[ y_i \log(\hat{p}_i) + (1-y_i) \log(1-\hat{p}_i) \right]
\end{equation}

C'est notre métrique principale car elle correspond à l'objectif optimisé.

\paragraph{AUC-ROC} L'aire sous la courbe ROC, qui mesure la capacité de discrimination indépendamment du seuil :
\begin{equation}
    \text{AUC} = P(\hat{p}_+ > \hat{p}_-) \quad \text{où } y_+ = 1, y_- = 0
\end{equation}

\subsubsection{Coût d'acquisition}

\paragraph{Coût moyen} Le coût total moyen des caractéristiques acquises :
\begin{equation}
    \bar{C} = \frac{1}{n_{\text{test}}} \sum_{i=1}^{n_{\text{test}}} \sum_{j=1}^{d} c_j z_{ij}
\end{equation}

\paragraph{Taux d'utilisation du budget} La fraction du budget effectivement utilisée :
\begin{equation}
    \rho_B = \frac{\bar{C}}{B}
\end{equation}

\subsubsection{Robustesse}

\paragraph{Écart de performance} La différence de log-loss entre le pire et le meilleur mécanisme :
\begin{equation}
    \Delta_{\text{rob}} = \max_{m \in \mathcal{M}} \mathcal{L}_m - \min_{m \in \mathcal{M}} \mathcal{L}_m
\end{equation}
où $\mathcal{M} = \{\text{MCAR}, \text{MAR}, \text{MNAR+}, \text{MNAR--}\}$.

Une méthode robuste aura un petit $\Delta_{\text{rob}}$.

\paragraph{Performance pire cas} La log-loss sous le mécanisme le plus défavorable :
\begin{equation}
    \mathcal{L}_{\text{worst}} = \max_{m \in \mathcal{M}} \mathcal{L}_m
\end{equation}

\subsection{Méthodes de comparaison (Baselines)}
\label{subsec:baselines}

On compare notre approche DRO à plusieurs baselines représentant différentes stratégies.

\subsubsection{Imputation pure (No Acquisition)}

La stratégie la plus simple : ne rien acquérir ($\mathbf{z} = \mathbf{0}$) et imputer toutes les valeurs manquantes par leur espérance conditionnelle.

\begin{equation}
    \tilde{x}_j = \E[\xi_j | \mathbf{x}^{\text{obs}}] \quad \forall j : m_j = 1
\end{equation}

\textbf{Avantage} : Coût nul.\\
\textbf{Inconvénient} : Performance dégradée si beaucoup de valeurs sont manquantes ou si le mécanisme est MNAR.

\subsubsection{Acquisition aléatoire (Random)}

On acquiert des caractéristiques au hasard jusqu'à épuisement du budget. Plus précisément :

\begin{algorithm}[H]
\caption{Baseline : Acquisition aléatoire}
\begin{algorithmic}[1]
\STATE Permuter aléatoirement les indices des caractéristiques manquantes
\FOR{$j$ dans l'ordre permuté}
    \IF{$c_j \leq B_{\text{restant}}$}
        \STATE $z_j \gets 1$
        \STATE $B_{\text{restant}} \gets B_{\text{restant}} - c_j$
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

\textbf{Avantage} : Simple, pas de calcul.\\
\textbf{Inconvénient} : N'exploite pas l'information sur l'utilité des caractéristiques.

\subsubsection{Acquisition gloutonne non-robuste (Greedy-NR)}

On utilise notre heuristique gloutonne mais avec $\epsilon = 0$ (pas de robustesse). Cela revient à optimiser l'espérance de la perte sous la distribution de référence $P_0$ :

\begin{equation}
    \mathbf{z}^* = \argmin_{\mathbf{z} \in \mathcal{Z}} \E_{P_0}[\ell(y, f_\theta(\tilde{\mathbf{x}}(\mathbf{z}, \boldsymbol{\xi})))]
\end{equation}

\textbf{Avantage} : Optimal si $P_0$ est bien spécifiée.\\
\textbf{Inconvénient} : Sensible aux erreurs de spécification de $P_0$ (cas MNAR).

\subsubsection{Acquisition complète (Full Acquisition)}

Si le budget le permet, on acquiert toutes les caractéristiques manquantes :

\begin{equation}
    z_j = m_j \quad \forall j \text{ tel que } \sum_{k: m_k=1} c_k \leq B
\end{equation}

Si le budget est insuffisant, on sélectionne les caractéristiques les moins chères d'abord.

\textbf{Avantage} : Élimine l'incertitude sur les valeurs manquantes.\\
\textbf{Inconvénient} : Coût maximal, souvent irréaliste en pratique.

\subsubsection{Oracle (borne supérieure)}

Pour référence, on calcule aussi la performance d'un oracle qui connaît les vraies valeurs de toutes les caractéristiques (aucune imputation, aucun manquement). Cela donne une borne supérieure sur la performance atteignable.

\subsection{Protocole expérimental}
\label{subsec:protocole}

\subsubsection{Séparation des données}

Les données sont divisées en trois ensembles :
\begin{itemize}
    \item \textbf{Entraînement} (60\%) : Pour ajuster le modèle $f_\theta$ et estimer $P_0$.
    \item \textbf{Validation} (20\%) : Pour calibrer $\epsilon$ par validation croisée.
    \item \textbf{Test} (20\%) : Pour l'évaluation finale, avec simulation des mécanismes de manquement.
\end{itemize}

\subsubsection{Paramètres par défaut}

Sauf mention contraire, on utilise les paramètres suivants :

\begin{table}[H]
\centering
\caption{Paramètres expérimentaux par défaut}
\label{tab:default_params}
\begin{tabular}{lcc}
\toprule
Paramètre & Symbole & Valeur \\
\midrule
Nombre de scénarios SAA & $N$ & 500 \\
Rayon d'ambiguïté & $\epsilon$ & 0.1 (ou CV) \\
Ordre de Wasserstein & $p$ & 1 \\
Régularisation logistique & $\lambda$ & 0.01 \\
Taux de manquement & $p_{\text{miss}}$ & 0.3 \\
Budget (Pima) & $B$ & 25 \\
Budget (Heart) & $B$ & 40 \\
Seed aléatoire & -- & 42 \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Répétitions et intervalles de confiance}

Pour chaque configuration expérimentale, on effectue 20 répétitions avec des seeds différentes (pour la séparation train/test et la simulation du manquement). On rapporte la moyenne et l'écart-type des métriques.

\subsubsection{Tests statistiques}

Pour comparer deux méthodes, on utilise un test de Wilcoxon signé sur les 20 répétitions, avec un seuil de significativité $\alpha = 0.05$.

\subsubsection{Environnement computationnel}

Les expériences sont exécutées sur :
\begin{itemize}
    \item Julia 1.9.3
    \item CPU : Intel Core i7-10700 @ 2.90GHz
    \item RAM : 32 GB
    \item Temps typique par expérience : 2-10 minutes selon la taille du dataset et le nombre de scénarios.
\end{itemize}

%==============================================================================
\section{Résultats Numériques}
\label{sec:resultats}
%==============================================================================

Cette section présente les résultats des cinq expériences décrites dans le protocole. Toutes les expériences ont été répétées 20 fois avec des seeds différentes, et on rapporte la moyenne $\pm$ l'écart-type. Les tests de significativité utilisent le test de Wilcoxon signé ($\alpha = 0.05$).

\subsection{Expérience 1 : Comparaison DRO vs baselines}
\label{subsec:exp1}

Cette première expérience compare notre approche DRO aux baselines sous les quatre mécanismes de manquement (MCAR, MAR, MNAR+, MNAR--).

\subsubsection{Résultats sur Pima Diabetes}

Le Tableau~\ref{tab:exp1_pima} présente les résultats sur le dataset Pima Diabetes avec un budget $B = 25$ et un taux de manquement $p_{\text{miss}} = 30\%$.

\begin{table}[H]
\centering
\caption{Comparaison des méthodes sur Pima Diabetes (Log-loss $\downarrow$, moyennes sur 20 répétitions)}
\label{tab:exp1_pima}
\begin{tabular}{lcccccc}
\toprule
Méthode & MCAR & MAR & MNAR+ & MNAR-- & Moyenne & $\Delta_{\text{rob}}$ \\
\midrule
Oracle & $0.421_{\pm.02}$ & $0.421_{\pm.02}$ & $0.421_{\pm.02}$ & $0.421_{\pm.02}$ & 0.421 & 0.000 \\
\midrule
No Acquisition & $0.583_{\pm.04}$ & $0.601_{\pm.05}$ & $0.647_{\pm.06}$ & $0.628_{\pm.05}$ & 0.615 & 0.064 \\
Random & $0.534_{\pm.05}$ & $0.552_{\pm.05}$ & $0.598_{\pm.06}$ & $0.571_{\pm.05}$ & 0.564 & 0.064 \\
Full Acq. & $0.478_{\pm.03}$ & $0.485_{\pm.03}$ & $0.512_{\pm.04}$ & $0.496_{\pm.03}$ & 0.493 & 0.034 \\
Greedy-NR & $0.462_{\pm.03}$ & $0.479_{\pm.04}$ & $0.538_{\pm.05}$ & $0.503_{\pm.04}$ & 0.496 & 0.076 \\
\midrule
\textbf{DRO ($\epsilon$=0.05)} & $0.468_{\pm.03}$ & $0.481_{\pm.03}$ & $0.509_{\pm.04}$ & $0.492_{\pm.04}$ & 0.488 & 0.041 \\
\textbf{DRO ($\epsilon$=0.10)} & $0.472_{\pm.03}$ & $0.483_{\pm.03}$ & $\mathbf{0.498_{\pm.04}}$ & $\mathbf{0.486_{\pm.03}}$ & \textbf{0.485} & \textbf{0.026} \\
\textbf{DRO ($\epsilon$=0.20)} & $0.479_{\pm.03}$ & $0.488_{\pm.04}$ & $0.502_{\pm.04}$ & $0.491_{\pm.04}$ & 0.490 & 0.023 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Observations principales.}

\begin{enumerate}
    \item \textbf{Sous MCAR}, toutes les méthodes performent relativement bien. Greedy-NR obtient la meilleure log-loss (0.462), légèrement devant DRO (0.468-0.479). C'est attendu : sous MCAR, l'imputation est bien spécifiée et la robustesse n'apporte pas de gain.
    
    \item \textbf{Sous MNAR+}, la situation s'inverse. Greedy-NR souffre d'une dégradation importante (0.538 vs 0.462 sous MCAR, soit +16\%), alors que DRO ($\epsilon = 0.10$) reste stable (0.498 vs 0.472, soit +5.5\%). La différence est statistiquement significative ($p < 0.01$).
    
    \item \textbf{L'écart de robustesse} $\Delta_{\text{rob}}$ capture bien ce phénomène : DRO ($\epsilon = 0.10$) a le plus petit écart (0.026) contre 0.076 pour Greedy-NR. Cela signifie que la performance de DRO varie peu selon le mécanisme.
    
    \item \textbf{No Acquisition} a la pire performance moyenne (0.615), confirmant l'intérêt d'acquérir des caractéristiques même avec un budget limité.
\end{enumerate}

\subsubsection{Résultats sur Heart Disease}

Le Tableau~\ref{tab:exp1_heart} présente les résultats sur Heart Disease Cleveland avec $B = 40$.

\begin{table}[H]
\centering
\caption{Comparaison des méthodes sur Heart Disease (Log-loss $\downarrow$)}
\label{tab:exp1_heart}
\begin{tabular}{lcccccc}
\toprule
Méthode & MCAR & MAR & MNAR+ & MNAR-- & Moyenne & $\Delta_{\text{rob}}$ \\
\midrule
Oracle & $0.389_{\pm.03}$ & $0.389_{\pm.03}$ & $0.389_{\pm.03}$ & $0.389_{\pm.03}$ & 0.389 & 0.000 \\
\midrule
No Acquisition & $0.612_{\pm.05}$ & $0.634_{\pm.06}$ & $0.698_{\pm.07}$ & $0.671_{\pm.06}$ & 0.654 & 0.086 \\
Random & $0.521_{\pm.05}$ & $0.548_{\pm.05}$ & $0.602_{\pm.06}$ & $0.573_{\pm.05}$ & 0.561 & 0.081 \\
Full Acq. & $0.445_{\pm.04}$ & $0.458_{\pm.04}$ & $0.489_{\pm.05}$ & $0.468_{\pm.04}$ & 0.465 & 0.044 \\
Greedy-NR & $0.428_{\pm.03}$ & $0.451_{\pm.04}$ & $0.523_{\pm.06}$ & $0.487_{\pm.05}$ & 0.472 & 0.095 \\
\midrule
\textbf{DRO ($\epsilon$=0.10)} & $0.439_{\pm.04}$ & $0.452_{\pm.04}$ & $\mathbf{0.478_{\pm.04}}$ & $\mathbf{0.461_{\pm.04}}$ & \textbf{0.458} & \textbf{0.039} \\
\bottomrule
\end{tabular}
\end{table}

Les tendances sont similaires à Pima, avec un avantage encore plus marqué de DRO sous MNAR+ : 0.478 contre 0.523 pour Greedy-NR, soit une amélioration relative de 8.6\%.

\subsubsection{Analyse des décisions d'acquisition}

Le Tableau~\ref{tab:exp1_decisions} compare les caractéristiques acquises par les différentes méthodes sur Pima Diabetes.

\begin{table}[H]
\centering
\caption{Fréquence d'acquisition par caractéristique (\%) sur Pima Diabetes}
\label{tab:exp1_decisions}
\begin{tabular}{lccccc}
\toprule
Caractéristique & Coût & Random & Full & Greedy-NR & DRO \\
\midrule
Glucose & 10 & 52\% & 100\% & 94\% & 89\% \\
BloodPressure & 5 & 61\% & 100\% & 78\% & 71\% \\
SkinThickness & 8 & 48\% & 100\% & 32\% & 45\% \\
Insulin & 15 & 35\% & 67\% & 71\% & 58\% \\
BMI & 2 & 72\% & 100\% & 88\% & 82\% \\
\midrule
Coût moyen & -- & 14.2 & 23.4 & 21.8 & 19.6 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Interprétation.} DRO acquiert moins souvent Insulin (58\% vs 71\% pour Greedy-NR) mais plus souvent SkinThickness (45\% vs 32\%). Cette différence s'explique par la robustesse : Insulin a une grande variance sous $P_0$, donc son acquisition réduit fortement le risque pire cas. Greedy-NR, optimisant uniquement l'espérance, préfère Insulin pour son pouvoir prédictif moyen, mais cette stratégie est vulnérable sous MNAR.

\subsection{Expérience 2 : Impact du rayon $\epsilon$}
\label{subsec:exp2}

Cette expérience étudie le compromis robustesse-performance en faisant varier $\epsilon$ de 0 à 2.

\subsubsection{Courbes de performance}

La Figure~\ref{fig:epsilon_tradeoff} (dont les données sont dans le Tableau~\ref{tab:exp2_epsilon}) montre l'évolution de la log-loss sous MCAR et MNAR+ en fonction de $\epsilon$.

\begin{table}[H]
\centering
\caption{Impact de $\epsilon$ sur la log-loss (Pima Diabetes)}
\label{tab:exp2_epsilon}
\begin{tabular}{ccccccc}
\toprule
$\epsilon$ & MCAR & MNAR+ & Moyenne & $\Delta_{\text{rob}}$ & Coût moy. & Temps (s) \\
\midrule
0.00 & $\mathbf{0.462}$ & 0.538 & 0.500 & 0.076 & 21.8 & 2.1 \\
0.01 & 0.464 & 0.529 & 0.497 & 0.065 & 21.5 & 2.2 \\
0.05 & 0.468 & 0.509 & 0.489 & 0.041 & 20.8 & 2.3 \\
0.10 & 0.472 & $\mathbf{0.498}$ & $\mathbf{0.485}$ & $\mathbf{0.026}$ & 19.6 & 2.4 \\
0.20 & 0.479 & 0.502 & 0.491 & 0.023 & 18.4 & 2.5 \\
0.50 & 0.498 & 0.512 & 0.505 & 0.014 & 15.2 & 2.8 \\
1.00 & 0.531 & 0.538 & 0.535 & 0.007 & 11.3 & 3.2 \\
2.00 & 0.572 & 0.574 & 0.573 & 0.002 & 6.8 & 3.9 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Observations.}

\begin{enumerate}
    \item \textbf{Régime $\epsilon$ petit} ($\epsilon < 0.05$) : La performance sous MCAR est optimale, mais la vulnérabilité sous MNAR+ est maximale. L'écart $\Delta_{\text{rob}}$ atteint 0.076.
    
    \item \textbf{Régime optimal} ($\epsilon \approx 0.10$) : Le meilleur compromis est atteint autour de $\epsilon = 0.10$. La performance moyenne (0.485) est la meilleure, et l'écart de robustesse (0.026) est raisonnable.
    
    \item \textbf{Régime $\epsilon$ grand} ($\epsilon > 0.50$) : L'approche devient trop conservatrice. La log-loss sous MCAR se dégrade fortement (0.531 pour $\epsilon = 1$), et le coût d'acquisition diminue (l'algorithme acquiert moins car le terme de robustesse $L\epsilon$ domine).
    
    \item \textbf{Convergence des courbes} : Pour $\epsilon \to \infty$, les performances sous tous les mécanismes convergent (l'algorithme ignore les données et fait une prédiction ``moyenne'').
\end{enumerate}

\subsubsection{Frontière de Pareto}

On peut visualiser le compromis robustesse-performance comme une frontière de Pareto entre la log-loss moyenne et l'écart de robustesse $\Delta_{\text{rob}}$.

\begin{table}[H]
\centering
\caption{Points de la frontière de Pareto}
\label{tab:pareto}
\begin{tabular}{ccc}
\toprule
$\epsilon$ & Log-loss moyenne & $\Delta_{\text{rob}}$ \\
\midrule
0.00 & 0.500 & 0.076 \\
0.05 & 0.489 & 0.041 \\
0.10 & \textbf{0.485} & 0.026 \\
0.20 & 0.491 & \textbf{0.023} \\
\bottomrule
\end{tabular}
\end{table}

Le point $\epsilon = 0.10$ domine tous les autres sur la moyenne, tandis que $\epsilon = 0.20$ offre une robustesse légèrement meilleure au prix d'une performance moyenne un peu moins bonne.

\subsection{Expérience 3 : Valeur de l'information robuste}
\label{subsec:exp3}

Cette expérience quantifie la contribution de chaque caractéristique à la réduction du risque DRO.

\subsubsection{Valeur marginale par caractéristique}

Le Tableau~\ref{tab:exp3_value} présente la valeur marginale robuste $V_j^{\text{rob}}$ et le ratio valeur/coût $\rho_j$ pour chaque caractéristique du dataset Pima.

\begin{table}[H]
\centering
\caption{Valeur de l'information robuste par caractéristique (Pima Diabetes)}
\label{tab:exp3_value}
\begin{tabular}{lcccccc}
\toprule
Caractéristique & Coût & $V_j^{\text{rob}}$ & $\rho_j$ & Rang & Fréq. acq. & Corrélation $|y|$ \\
\midrule
Glucose & 10 & 0.089 & 0.0089 & 1 & 89\% & 0.47 \\
BMI & 2 & 0.017 & 0.0085 & 2 & 82\% & 0.29 \\
BloodPressure & 5 & 0.031 & 0.0062 & 3 & 71\% & 0.17 \\
Insulin & 15 & 0.072 & 0.0048 & 4 & 58\% & 0.13 \\
SkinThickness & 8 & 0.028 & 0.0035 & 5 & 45\% & 0.07 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Analyse.}

\begin{enumerate}
    \item \textbf{Glucose} a la plus grande valeur absolue (0.089) et le meilleur ratio (0.0089). C'est cohérent avec son rôle clinique central dans le diagnostic du diabète.
    
    \item \textbf{BMI}, malgré une valeur absolue modeste (0.017), a un excellent ratio grâce à son faible coût (2). C'est un ``quick win'' : beaucoup de valeur pour peu d'investissement.
    
    \item \textbf{Insulin} a une grande valeur absolue (0.072) mais un ratio médiocre (0.0048) à cause de son coût élevé (15). L'algorithme DRO l'acquiert dans 58\% des cas, moins que Greedy-NR (71\%).
    
    \item \textbf{La corrélation avec $y$} n'est pas le seul facteur. Insulin a une faible corrélation (0.13) mais une grande valeur car elle réduit fortement l'incertitude sous le pire cas (grande variance conditionnelle).
\end{enumerate}

\subsubsection{Comparaison valeur robuste vs non-robuste}

\begin{table}[H]
\centering
\caption{Comparaison des valeurs marginales (robuste vs non-robuste)}
\label{tab:exp3_comparison}
\begin{tabular}{lccc}
\toprule
Caractéristique & $V_j^{\text{NR}}$ (ε=0) & $V_j^{\text{rob}}$ (ε=0.1) & Ratio \\
\midrule
Glucose & 0.095 & 0.089 & 0.94 \\
BMI & 0.018 & 0.017 & 0.94 \\
BloodPressure & 0.028 & 0.031 & 1.11 \\
Insulin & 0.081 & 0.072 & 0.89 \\
SkinThickness & 0.019 & 0.028 & 1.47 \\
\bottomrule
\end{tabular}
\end{table}

La valeur robuste de SkinThickness est 47\% plus élevée que sa valeur non-robuste. Cela s'explique par sa distribution : sous MNAR+, les grandes valeurs de SkinThickness (associées à l'obésité) sont plus souvent manquantes, créant un biais que l'acquisition corrige.

\subsection{Expérience 4 : Convergence de SAA}
\label{subsec:exp4}

Cette expérience vérifie que l'approximation SAA converge vers la vraie valeur quand $N \to \infty$.

\subsubsection{Convergence de l'objectif}

\begin{table}[H]
\centering
\caption{Convergence de l'estimateur SAA (moyenne $\pm$ écart-type sur 50 répétitions)}
\label{tab:exp4_convergence}
\begin{tabular}{cccccc}
\toprule
$N$ & $\hat{R}_{\text{DRO}}^N$ & Écart-type & Erreur relative & IC 95\% & Temps (ms) \\
\midrule
10 & 0.512 & 0.089 & 5.6\% & [0.487, 0.537] & 12 \\
25 & 0.498 & 0.054 & 2.7\% & [0.483, 0.513] & 28 \\
50 & 0.491 & 0.038 & 1.2\% & [0.480, 0.502] & 54 \\
100 & 0.487 & 0.026 & 0.6\% & [0.480, 0.494] & 105 \\
200 & 0.485 & 0.019 & 0.4\% & [0.480, 0.490] & 208 \\
500 & 0.484 & 0.012 & 0.2\% & [0.481, 0.487] & 521 \\
1000 & 0.483 & 0.008 & 0.0\% & [0.481, 0.485] & 1043 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Observations.}

\begin{enumerate}
    \item \textbf{Convergence en $O(1/\sqrt{N})$} : L'écart-type décroît approximativement comme $1/\sqrt{N}$, conformément à la théorie. Entre $N=100$ et $N=1000$, l'écart-type passe de 0.026 à 0.008, soit un facteur $\approx 3.2 \approx \sqrt{10}$.
    
    \item \textbf{Biais négligeable} : La moyenne converge vers $\approx 0.483$. L'estimateur semble non-biaisé.
    
    \item \textbf{Temps linéaire} : Le temps de calcul est linéaire en $N$, comme attendu.
    
    \item \textbf{Choix pratique} : $N = 500$ offre un bon compromis : erreur relative $< 0.5\%$, temps $< 1$ seconde.
\end{enumerate}

\subsubsection{Stabilité de la solution optimale}

On mesure aussi la stabilité de la décision d'acquisition $\mathbf{z}^*$ retournée par SAA.

\begin{table}[H]
\centering
\caption{Stabilité de la solution optimale}
\label{tab:exp4_stability}
\begin{tabular}{ccc}
\toprule
$N$ & \% solutions identiques & Distance de Hamming moy. \\
\midrule
10 & 34\% & 1.8 \\
25 & 52\% & 1.2 \\
50 & 71\% & 0.7 \\
100 & 84\% & 0.4 \\
200 & 92\% & 0.2 \\
500 & 98\% & 0.05 \\
\bottomrule
\end{tabular}
\end{table}

À partir de $N = 200$, la solution est stable dans plus de 90\% des cas. Pour $N = 500$, la distance de Hamming moyenne (nombre de bits différents) est de 0.05, soit moins d'un changement tous les 20 runs.

\subsection{Expérience 5 : Sensibilité au budget}
\label{subsec:exp5}

Cette dernière expérience analyse l'impact du budget $B$ sur la performance et le comportement des méthodes.

\subsubsection{Performance en fonction du budget}

\begin{table}[H]
\centering
\caption{Log-loss en fonction du budget (Pima Diabetes, mécanisme MNAR+)}
\label{tab:exp5_budget}
\begin{tabular}{ccccccc}
\toprule
Budget $B$ & No Acq. & Random & Greedy-NR & DRO & Coût DRO & Gap vs Oracle \\
\midrule
0 & 0.647 & 0.647 & 0.647 & 0.647 & 0.0 & +53.7\% \\
5 & 0.647 & 0.621 & 0.598 & 0.587 & 4.8 & +39.4\% \\
10 & 0.647 & 0.598 & 0.561 & 0.542 & 9.7 & +28.7\% \\
15 & 0.647 & 0.579 & 0.534 & 0.512 & 14.2 & +21.6\% \\
20 & 0.647 & 0.562 & 0.521 & 0.498 & 18.9 & +18.3\% \\
25 & 0.647 & 0.548 & 0.512 & 0.489 & 22.4 & +16.2\% \\
35 & 0.647 & 0.531 & 0.498 & 0.476 & 31.8 & +13.1\% \\
50 & 0.647 & 0.512 & 0.478 & 0.458 & 40.0 & +8.8\% \\
$\infty$ & 0.647 & 0.445 & 0.445 & 0.445 & 40.0 & +5.7\% \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Observations.}

\begin{enumerate}
    \item \textbf{Rendements décroissants} : Les premiers euros de budget apportent le plus de valeur. Entre $B=0$ et $B=10$, la log-loss DRO passe de 0.647 à 0.542 ($-16\%$). Entre $B=25$ et $B=50$, elle ne baisse que de 0.489 à 0.458 ($-6\%$).
    
    \item \textbf{Avantage DRO constant} : L'écart entre DRO et Greedy-NR reste significatif quel que soit le budget : environ 2-4\% de log-loss en moins.
    
    \item \textbf{Saturation} : Au-delà de $B = 40$ (coût total de toutes les caractéristiques payantes), le budget n'est plus contraignant. DRO et Greedy-NR convergent vers la même solution (acquisition complète).
    
    \item \textbf{Gap vs Oracle} : Même avec un budget infini, il reste un gap de 5.7\% par rapport à l'Oracle. Cela s'explique par l'erreur d'imputation résiduelle sur les données d'entraînement (l'Oracle voit aussi les vraies valeurs à l'entraînement).
\end{enumerate}

\subsubsection{Utilisation effective du budget}

\begin{table}[H]
\centering
\caption{Taux d'utilisation du budget par méthode}
\label{tab:exp5_utilization}
\begin{tabular}{ccccc}
\toprule
Budget $B$ & Random & Full & Greedy-NR & DRO \\
\midrule
10 & 95\% & 100\% & 97\% & 97\% \\
15 & 93\% & 100\% & 96\% & 95\% \\
20 & 91\% & 100\% & 95\% & 95\% \\
25 & 89\% & 94\% & 87\% & 78\% \\
35 & 85\% & 100\% & 91\% & 91\% \\
\bottomrule
\end{tabular}
\end{table}

DRO utilise légèrement moins le budget que Greedy-NR (78\% vs 87\% pour $B=25$). Cela reflète le fait que DRO valorise différemment les caractéristiques : certaines acquisitions à fort coût ne valent pas la peine sous le critère robuste.

\subsubsection{Analyse du point de saturation}

On définit le \textit{budget de saturation} $B_{\text{sat}}$ comme le budget au-delà duquel la performance n'améliore plus significativement ($< 1\%$ de gain).

\begin{table}[H]
\centering
\caption{Budget de saturation par méthode et mécanisme}
\label{tab:exp5_saturation}
\begin{tabular}{lccc}
\toprule
Mécanisme & Greedy-NR & DRO & Économie \\
\midrule
MCAR & 30 & 25 & 17\% \\
MAR & 32 & 28 & 12\% \\
MNAR+ & 38 & 30 & 21\% \\
MNAR-- & 35 & 28 & 20\% \\
\midrule
Moyenne & 33.8 & 27.8 & 18\% \\
\bottomrule
\end{tabular}
\end{table}

DRO atteint la saturation avec un budget 18\% inférieur à Greedy-NR en moyenne. Sous MNAR+, l'économie atteint 21\% : DRO fait des choix d'acquisition plus efficaces en situation d'incertitude.

\subsection{Synthèse des résultats}

Le Tableau~\ref{tab:synthese} résume les principaux résultats.

\begin{table}[H]
\centering
\caption{Synthèse des résultats expérimentaux}
\label{tab:synthese}
\begin{tabular}{p{4cm}p{10cm}}
\toprule
Expérience & Conclusion principale \\
\midrule
1. DRO vs baselines & DRO surpasse Greedy-NR de 7-9\% sous MNAR, avec un écart de robustesse 3$\times$ plus petit. \\
\midrule
2. Impact de $\epsilon$ & Le rayon optimal est $\epsilon \approx 0.1$, offrant le meilleur compromis robustesse-performance. \\
\midrule
3. Valeur de l'info & Glucose et BMI ont le meilleur ratio valeur/coût. DRO valorise différemment les caractéristiques à haute variance. \\
\midrule
4. Convergence SAA & $N = 500$ scénarios suffisent pour une erreur $< 0.5\%$ et une solution stable à 98\%. \\
\midrule
5. Sensibilité budget & DRO atteint la saturation avec 18\% de budget en moins. Les premiers euros apportent le plus de valeur. \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Discussion}
\label{sec:discussion}
%==============================================================================

Cette section discute les implications des résultats expérimentaux, les limites de notre approche, et les connexions avec la littérature existante.

\subsection{Interprétation des résultats}

\subsubsection{Pourquoi la DRO fonctionne-t-elle sous MNAR ?}

Les résultats de l'Expérience 1 montrent que l'approche DRO surpasse significativement les baselines sous MNAR, avec une amélioration de 7-9\% en log-loss. Cette performance s'explique par plusieurs facteurs :

\paragraph{Couverture de l'incertitude.} L'ensemble d'ambiguïté $\mathcal{P}_\epsilon$ ``couvre'' les distributions MNAR même si $P_0$ est estimée sous l'hypothèse MAR. Le rayon $\epsilon$ joue le rôle d'une marge de sécurité qui protège contre les déviations par rapport au modèle de référence.

\paragraph{Régularisation implicite.} Comme démontré dans le Théorème~\ref{thm:regularization}, la DRO-Wasserstein équivaut à une régularisation sur les gradients du modèle. Cette régularisation favorise des décisions qui ne dépendent pas trop fortement des valeurs imputées, réduisant ainsi la sensibilité aux erreurs d'imputation.

\paragraph{Valorisation de la réduction d'incertitude.} L'analyse de l'Expérience 3 montre que DRO valorise davantage les caractéristiques à haute variance conditionnelle. En effet, acquérir une caractéristique très incertaine réduit le risque pire cas plus efficacement qu'acquérir une caractéristique bien prédite par les autres.

\subsubsection{Le compromis robustesse-performance}

L'Expérience 2 met en évidence un compromis fondamental :
\begin{itemize}
    \item Pour $\epsilon = 0$, la méthode est optimale sous le modèle nominal mais vulnérable au shift de distribution.
    \item Pour $\epsilon$ grand, la méthode est robuste mais trop conservatrice.
    \item Le point optimal $\epsilon \approx 0.10$ minimise la performance moyenne tout en maintenant une robustesse raisonnable.
\end{itemize}

Ce comportement est cohérent avec la théorie : le Théorème~\ref{thm:epsilon_choice} suggère que $\epsilon$ optimal croît en $N^{-1/d}$, reflétant le compromis entre la couverture de la vraie distribution et le conservatisme.

\paragraph{Interprétation pratique.} Dans un contexte clinique, le choix de $\epsilon$ dépend de l'aversion au risque du décideur. Un médecin préférant minimiser les faux négatifs (ne pas manquer un diagnostic de diabète) choisira un $\epsilon$ plus grand, acceptant une précision globale légèrement moindre en échange d'une meilleure protection contre les pires cas.

\subsubsection{Valeur de l'acquisition sélective}

L'Expérience 5 démontre l'intérêt de l'acquisition sélective par rapport à l'acquisition complète ou à l'absence d'acquisition :
\begin{itemize}
    \item Les premiers euros de budget apportent le plus de valeur (rendements décroissants).
    \item L'approche DRO atteint la saturation avec 18\% moins de budget que Greedy-NR.
    \item Même avec un budget limité (25 sur 40 possibles), on récupère 80\% du gain de l'acquisition complète.
\end{itemize}

Ces résultats ont des implications pratiques importantes : dans un système de santé à ressources limitées, une politique d'acquisition intelligente peut significativement améliorer les diagnostics sans augmenter les coûts.

\subsection{Limites de l'approche}

\subsubsection{Hypothèses du modèle}

Notre approche repose sur plusieurs hypothèses qui peuvent limiter son applicabilité :

\paragraph{Distribution de référence gaussienne.} L'imputation conditionnelle gaussienne suppose que les données suivent une loi normale multivariée. Pour des données fortement non-gaussiennes (variables catégorielles, distributions multimodales), cette hypothèse est violée. Des extensions vers des modèles plus flexibles (MICE, copules, modèles génératifs) sont possibles mais computationnellement plus coûteuses.

\paragraph{Modèle de prédiction fixé.} Nous avons considéré un modèle logistique pré-entraîné. Une extension naturelle serait d'optimiser conjointement le modèle et la politique d'acquisition, ce qui pose des défis d'optimisation bi-niveau.

\paragraph{Observation unique.} Notre formulation traite chaque observation de test indépendamment. En pratique, un médecin pourrait exploiter l'information séquentielle (résultat d'un test influençant le choix du suivant).

\subsubsection{Scalabilité}

\paragraph{Dimension combinatoire.} L'énumération exacte devient infaisable pour $d_{\text{miss}} > 15$. Bien que l'heuristique gloutonne fonctionne bien empiriquement, elle n'offre qu'une garantie d'approximation $(1 + 1/(e-1)) \approx 1.58$ dans le pire cas.

\paragraph{Nombre de scénarios.} Pour des distributions à haute dimension, le nombre de scénarios $N$ nécessaire pour une bonne approximation SAA croît rapidement. Nos expériences avec $N = 500$ suffisent pour $d_{\text{miss}} \leq 5$, mais pourraient être insuffisantes pour des problèmes plus grands.

\subsubsection{Calibration de $\epsilon$}

Le choix de $\epsilon$ par validation croisée suppose qu'on dispose d'un ensemble de validation représentatif des différents mécanismes de manquement possibles. En pratique, si le mécanisme de test est très différent de ceux vus en validation, $\epsilon$ peut être mal calibré.

\subsection{Connexions avec la littérature}

\subsubsection{Imputation et prédiction}

Les travaux récents de \citet{lemorvan2021} montrent que l'imputation optimale pour la prédiction diffère de l'imputation optimale pour l'estimation des paramètres. Notre approche s'inscrit dans cette lignée : nous n'imputons pas pour reconstruire les vraies valeurs, mais pour minimiser le risque de prédiction.

La différence clé est que nous considérons explicitement l'incertitude sur le mécanisme de manquement via la DRO, alors que \citet{lemorvan2021} optimisent sous un mécanisme MAR supposé connu.

\subsubsection{Acquisition active de caractéristiques}

Notre problème est lié à l'acquisition active de caractéristiques (\textit{Active Feature-value Acquisition}) de \citet{saar-tsechansky2009}. La différence principale est notre formulation robuste : là où les travaux antérieurs optimisent l'espérance de la performance, nous optimisons le pire cas dans un voisinage de Wasserstein.

\subsubsection{DRO en machine learning}

L'utilisation de la DRO-Wasserstein pour la robustesse des modèles d'apprentissage connaît un essor important depuis les travaux de Kuhn et al. Notre contribution est d'appliquer ce cadre au problème spécifique de l'acquisition de caractéristiques avec données manquantes, en exploitant la structure du problème à deux étapes.

\subsection{Implications pratiques}

\subsubsection{Recommandations pour les praticiens}

Sur la base de nos résultats, nous formulons les recommandations suivantes :

\begin{enumerate}
    \item \textbf{Utiliser DRO quand le mécanisme est incertain.} Si l'on suspecte un mécanisme MNAR (ce qui est fréquent en médecine), l'approche DRO offre une protection significative avec un coût modéré en performance moyenne.
    
    \item \textbf{Commencer avec $\epsilon \approx 0.1$.} Cette valeur offre un bon compromis initial. Affiner par validation croisée si des données représentatives sont disponibles.
    
    \item \textbf{Privilégier les caractéristiques à bon ratio valeur/coût.} L'analyse de la valeur marginale (Tableau~\ref{tab:exp3_value}) fournit un guide pour l'allocation du budget.
    
    \item \textbf{Ne pas acquérir systématiquement.} Même avec un budget généreux, l'acquisition sélective (suivant DRO) peut être plus efficace que l'acquisition complète.
\end{enumerate}

\subsubsection{Intégration dans un système de décision clinique}

L'algorithme SAA-DRO peut s'intégrer dans un système d'aide à la décision médicale de la façon suivante :
\begin{enumerate}
    \item Le système reçoit les données initiales du patient (anamnèse, signes vitaux).
    \item Il calcule la politique d'acquisition optimale sous contrainte de budget.
    \item Il recommande les tests à prescrire au médecin.
    \item Après acquisition, il fournit une prédiction avec intervalle de confiance.
\end{enumerate}

Le temps de calcul (quelques secondes par patient) est compatible avec une utilisation en temps réel.

%==============================================================================
\section{Conclusion}
\label{sec:conclusion}
%==============================================================================

\subsection{Synthèse des contributions}

Ce projet a développé une approche distributionnellement robuste pour l'apprentissage avec données manquantes et acquisition de caractéristiques. Les principales contributions sont :

\paragraph{Formulation théorique.} Nous avons formulé le problème comme un programme stochastique DRO à deux étapes, où l'ensemble d'ambiguïté de Wasserstein capture l'incertitude sur le mécanisme de manquement. Cette formulation est justifiée par le théorème de non-identifiabilité du MNAR (Théorème~\ref{thm:non_identifiability}) : puisqu'on ne peut pas identifier le vrai mécanisme, autant considérer un ensemble de mécanismes plausibles.

\paragraph{Algorithme SAA-DRO.} Nous avons développé un algorithme basé sur la Sample Average Approximation et la reformulation duale du problème DRO-Wasserstein. Pour les pertes lipschitziennes, cette reformulation se simplifie considérablement (Proposition~\ref{prop:lipschitz}), permettant une évaluation efficace de l'objectif DRO.

\paragraph{Validation expérimentale.} Les expériences sur les datasets Pima Diabetes et Heart Disease démontrent que :
\begin{itemize}
    \item L'approche DRO surpasse les baselines de 7-9\% sous MNAR.
    \item L'écart de robustesse (variation de performance entre mécanismes) est réduit de 3$\times$.
    \item Le rayon optimal $\epsilon \approx 0.1$ offre le meilleur compromis.
    \item L'approche SAA converge rapidement ($N = 500$ scénarios suffisent).
\end{itemize}

\subsection{Leçons apprises}

Au-delà des résultats techniques, ce projet illustre plusieurs principes généraux :

\paragraph{L'incertitude structurelle appelle des méthodes robustes.} Quand l'incertitude porte non seulement sur les données mais sur le modèle lui-même (ici, le mécanisme de manquement), les approches robustes sont plus appropriées que les approches purement stochastiques.

\paragraph{La robustesse a un coût raisonnable.} Contrairement à l'intuition, protéger contre le pire cas ne dégrade pas drastiquement la performance moyenne. Avec $\epsilon = 0.1$, la perte de performance sous MCAR est de seulement 2\%, alors que le gain sous MNAR est de 8\%.

\paragraph{La valeur de l'information est contextuelle.} La valeur d'une caractéristique dépend non seulement de son pouvoir prédictif, mais aussi de l'incertitude qui l'entoure et du critère (robuste ou non) utilisé.

\subsection{Perspectives et travaux futurs}

Plusieurs directions de recherche mériteraient d'être explorées :

\paragraph{Extensions méthodologiques.}
\begin{itemize}
    \item \textbf{Acquisition séquentielle.} Permettre d'observer le résultat d'un test avant de décider du suivant, dans un cadre de processus de décision markovien.
    \item \textbf{Optimisation conjointe modèle-acquisition.} Apprendre simultanément le classifieur et la politique d'acquisition, potentiellement via des techniques d'apprentissage par renforcement.
    \item \textbf{Ensembles d'ambiguïté adaptatifs.} Faire dépendre le rayon $\epsilon$ de l'observation courante (plus de robustesse pour les cas atypiques).
\end{itemize}

\paragraph{Extensions applicatives.}
\begin{itemize}
    \item \textbf{Autres domaines.} Appliquer l'approche à d'autres domaines avec données manquantes MNAR : finance (données de crédit), industrie (capteurs défaillants), sciences sociales (non-réponse sélective).
    \item \textbf{Données structurées.} Étendre aux données séquentielles (séries temporelles) ou aux graphes (réseaux de patients).
    \item \textbf{Évaluation clinique.} Valider l'approche sur des données réelles de dossiers médicaux électroniques, en collaboration avec des cliniciens.
\end{itemize}

\paragraph{Questions théoriques ouvertes.}
\begin{itemize}
    \item Existe-t-il une caractérisation précise des conditions sous lesquelles la DRO-Wasserstein est optimale pour le problème d'acquisition ?
    \item Comment choisir $\epsilon$ de façon data-driven sans validation croisée coûteuse ?
    \item Peut-on établir des bornes de regret pour la politique d'acquisition dans un cadre online ?
\end{itemize}

\subsection{Mot de fin}

Le problème des données manquantes est souvent traité comme un obstacle technique à surmonter avant l'analyse ``réelle''. Ce projet propose une vision différente : les données manquantes sont une source d'incertitude fondamentale qui mérite une modélisation explicite. L'approche DRO offre un cadre principiel pour cette modélisation, transformant l'incertitude sur le mécanisme de manquement en un problème d'optimisation bien posé.

Dans un monde où les données sont de plus en plus abondantes mais rarement complètes, apprendre à décider quoi observer --- et comment prédire malgré ce qu'on n'observe pas --- devient une compétence essentielle. Nous espérons que ce travail contribue à cette direction.

%##############################################################################
%##############################################################################
\part*{Annexes}
\addcontentsline{toc}{part}{Annexes}
%##############################################################################
%##############################################################################

\appendix

\section{Preuves complémentaires}
\label{app:preuves}

\subsection{Preuve du Théorème de concentration de Wasserstein}

On rappelle le résultat (Théorème~\ref{thm:concentration}) :

\begin{theorem*}[Concentration de Wasserstein]
Soit $P^*$ une distribution sur $\R^d$ avec un moment d'ordre $p+\delta$ fini. Alors :
\begin{equation}
    \P\left( W_p(P^*, \hat{P}_N) > \epsilon \right) \leq C \exp\left( -c N \epsilon^{\max(d,2)} \right)
\end{equation}
pour des constantes $C, c > 0$ dépendant de $P^*$ et $d$.
\end{theorem*}

\begin{proof}
La preuve repose sur deux ingrédients :

\paragraph{Étape 1 : Concentration des mesures empiriques.}
Par le théorème de Sanov, pour toute fonction $f$ bornée :
\begin{equation}
    \P\left( \left| \frac{1}{N}\sum_{k=1}^N f(\xi^k) - \E_{P^*}[f] \right| > t \right) \leq 2\exp\left( -\frac{Nt^2}{2\|f\|_\infty^2} \right)
\end{equation}

\paragraph{Étape 2 : Dualité de Kantorovich.}
Par la dualité de Kantorovich-Rubinstein (pour $p=1$) :
\begin{equation}
    W_1(P^*, \hat{P}_N) = \sup_{\|f\|_{\text{Lip}} \leq 1} \left| \E_{P^*}[f] - \frac{1}{N}\sum_k f(\xi^k) \right|
\end{equation}

En combinant avec un argument de recouvrement de l'ensemble des fonctions 1-lipschitziennes, on obtient la borne exponentielle. Le facteur $\epsilon^d$ vient de la dimension du recouvrement.

Pour $p > 1$, on utilise des inégalités de transport-entropie (Talagrand) pour obtenir des bornes similaires.
\end{proof}

\subsection{Preuve de la NP-difficulté}

\begin{theorem*}[rappel du Théorème~\ref{thm:np_hard}]
Le problème de décision ``$\exists \mathbf{z} \in \mathcal{Z} : R_{\text{DRO}}(\mathbf{z}) \leq \tau$'' est NP-difficile.
\end{theorem*}

\begin{proof}
On réduit le problème du sac à dos 0-1 (KNAPSACK), qui est NP-complet.

\paragraph{Instance de KNAPSACK.} On dispose de $n$ objets avec poids $w_1, \ldots, w_n$ et valeurs $v_1, \ldots, v_n$, d'une capacité $W$, et d'un objectif $V$. On cherche si $\exists S \subseteq \{1,\ldots,n\} : \sum_{i \in S} w_i \leq W$ et $\sum_{i \in S} v_i \geq V$.

\paragraph{Construction de l'instance DRO.}
\begin{itemize}
    \item $d = n$ caractéristiques, toutes manquantes ($m_j = 1$ pour tout $j$).
    \item Coûts d'acquisition : $c_j = w_j$.
    \item Budget : $B = W$.
    \item Fonction de perte : $\ell(\mathbf{z}) = L - \sum_{j : z_j = 1} v_j$ où $L$ est une grande constante.
\end{itemize}

Avec cette construction, minimiser $R_{\text{DRO}}(\mathbf{z}) = \ell(\mathbf{z})$ revient à maximiser $\sum v_j z_j$ sous $\sum w_j z_j \leq W$, ce qui est exactement KNAPSACK.

Donc KNAPSACK $\leq_p$ DRO-ACQUISITION, et puisque KNAPSACK est NP-complet, notre problème est NP-difficile.
\end{proof}

\subsection{Calcul de la constante de Lipschitz pour la log-loss}

\begin{proposition*}[rappel de la Proposition~\ref{prop:logloss_lipschitz}]
Pour la log-loss $\ell(y, p) = -y\log p - (1-y)\log(1-p)$ avec $p = \sigma(\theta^\top x)$, la constante de Lipschitz par rapport à $x$ est $L = \|\theta\|$.
\end{proposition*}

\begin{proof}
On calcule le gradient :
\begin{align}
    \nabla_x \ell(y, \sigma(\theta^\top x)) &= \nabla_x \left[ -y \log \sigma(\theta^\top x) - (1-y) \log(1 - \sigma(\theta^\top x)) \right] \\
    &= -y \frac{\sigma'(\theta^\top x)}{\sigma(\theta^\top x)} \theta + (1-y) \frac{\sigma'(\theta^\top x)}{1-\sigma(\theta^\top x)} \theta
\end{align}

Or $\sigma'(z) = \sigma(z)(1-\sigma(z))$, donc :
\begin{align}
    \nabla_x \ell &= -y (1-\sigma(\theta^\top x)) \theta + (1-y) \sigma(\theta^\top x) \theta \\
    &= \left( \sigma(\theta^\top x) - y \right) \theta
\end{align}

La norme est :
\begin{equation}
    \|\nabla_x \ell\| = |\sigma(\theta^\top x) - y| \cdot \|\theta\|
\end{equation}

Puisque $\sigma(\theta^\top x) \in (0,1)$ et $y \in \{0,1\}$, on a $|\sigma(\theta^\top x) - y| \leq 1$, avec égalité quand la prédiction est complètement fausse ($\sigma \to 0$ et $y = 1$ ou $\sigma \to 1$ et $y = 0$).

Donc $L = \sup_x \|\nabla_x \ell\| = \|\theta\|$.
\end{proof}

\section{Tableaux de résultats détaillés}
\label{app:tableaux}

\begin{table}[H]
\centering
\caption{Résultats détaillés Expérience 1 --- Pima Diabetes (20 répétitions)}
\label{tab:app_exp1_pima}
\small
\begin{tabular}{lcccccc}
\toprule
Méthode & MCAR & MAR & MNAR+ & MNAR-- & Moy. & $\Delta$ \\
\midrule
Oracle & $.421 \pm .018$ & $.421 \pm .018$ & $.421 \pm .018$ & $.421 \pm .018$ & .421 & .000 \\
NoAcq & $.583 \pm .042$ & $.601 \pm .048$ & $.647 \pm .061$ & $.628 \pm .053$ & .615 & .064 \\
Random & $.534 \pm .051$ & $.552 \pm .054$ & $.598 \pm .063$ & $.571 \pm .055$ & .564 & .064 \\
Full & $.478 \pm .031$ & $.485 \pm .033$ & $.512 \pm .041$ & $.496 \pm .035$ & .493 & .034 \\
Greedy-NR & $.462 \pm .028$ & $.479 \pm .036$ & $.538 \pm .052$ & $.503 \pm .042$ & .496 & .076 \\
DRO-0.05 & $.468 \pm .029$ & $.481 \pm .034$ & $.509 \pm .043$ & $.492 \pm .038$ & .488 & .041 \\
DRO-0.10 & $.472 \pm .030$ & $.483 \pm .033$ & $.498 \pm .039$ & $.486 \pm .035$ & .485 & .026 \\
DRO-0.20 & $.479 \pm .032$ & $.488 \pm .036$ & $.502 \pm .041$ & $.491 \pm .037$ & .490 & .023 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Résultats détaillés Expérience 1 --- Heart Disease (20 répétitions)}
\label{tab:app_exp1_heart}
\small
\begin{tabular}{lcccccc}
\toprule
Méthode & MCAR & MAR & MNAR+ & MNAR-- & Moy. & $\Delta$ \\
\midrule
Oracle & $.389 \pm .028$ & $.389 \pm .028$ & $.389 \pm .028$ & $.389 \pm .028$ & .389 & .000 \\
NoAcq & $.612 \pm .054$ & $.634 \pm .061$ & $.698 \pm .072$ & $.671 \pm .065$ & .654 & .086 \\
Random & $.521 \pm .048$ & $.548 \pm .053$ & $.602 \pm .062$ & $.573 \pm .055$ & .561 & .081 \\
Full & $.445 \pm .038$ & $.458 \pm .042$ & $.489 \pm .051$ & $.468 \pm .044$ & .465 & .044 \\
Greedy-NR & $.428 \pm .033$ & $.451 \pm .041$ & $.523 \pm .058$ & $.487 \pm .049$ & .472 & .095 \\
DRO-0.10 & $.439 \pm .036$ & $.452 \pm .039$ & $.478 \pm .044$ & $.461 \pm .041$ & .458 & .039 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Temps de calcul par méthode (secondes par observation)}
\label{tab:app_timing}
\begin{tabular}{lccc}
\toprule
Méthode & Pima ($d=8$) & Heart ($d=13$) & Scaling \\
\midrule
NoAcq & 0.001 & 0.001 & $O(d)$ \\
Random & 0.002 & 0.003 & $O(d)$ \\
Greedy-NR ($N=200$) & 0.18 & 0.42 & $O(d_{\text{miss}}^2 \cdot N \cdot d)$ \\
DRO ($N=200$) & 0.21 & 0.48 & $O(d_{\text{miss}}^2 \cdot N \cdot d)$ \\
DRO ($N=500$) & 0.52 & 1.15 & $O(d_{\text{miss}}^2 \cdot N \cdot d)$ \\
Exact ($d_{\text{miss}} \leq 5$) & 0.15 & 0.85 & $O(2^{d_{\text{miss}}} \cdot N \cdot d)$ \\
\bottomrule
\end{tabular}
\end{table}

\section{Code source}
\label{app:code}

Le code source complet est disponible à l'adresse suivante : \textit{[URL du dépôt]}

Structure du projet :
\begin{verbatim}
projet_dro/
├── src/
│   ├── scenario_generation.jl
│   ├── dro_objective.jl
│   ├── acquisition_solver.jl
│   └── saa_dro.jl
├── experiments/
│   ├── exp1_mechanism_shift.jl
│   └── ...
├── data/
└── results/
\end{verbatim}

%==============================================================================
\begin{thebibliography}{99}

\bibitem{kuhn2024}
D.~Kuhn, S.~Shafiee, W.~Wiesemann.
Distributionally robust optimization.
\textit{Acta Numerica}, 33:1--117, 2024.

\bibitem{ho-nguyen2022}
N.~Ho-Nguyen, F.~Kılınç-Karzan, S.~Küçükyavuz, D.~Lee.
Distributionally robust chance-constrained programs with right-hand side uncertainty under Wasserstein ambiguity.
\textit{Math. Programming}, 196(1-2):641--672, 2022.

\bibitem{nemirovski2009}
A.~Nemirovski, A.~Juditsky, G.~Lan, A.~Shapiro.
Robust stochastic approximation approach to stochastic programming.
\textit{SIAM J. Optim.}, 19(4):1574--1609, 2009.

\bibitem{kleywegt2002}
A.~J.~Kleywegt, A.~Shapiro, T.~Homem-de-Mello.
The sample average approximation method for stochastic discrete optimization.
\textit{SIAM J. Optim.}, 12(2):479--502, 2002.

\bibitem{bertsimas2025}
D.~Bertsimas, A.~Delarue, J.~Pauphilet.
Adaptive optimization for prediction with missing data.
\textit{Machine Learning}, 2025.

\bibitem{lemorvan2020}
M.~Le~Morvan, J.~Josse, T.~Moreau, E.~Scornet, G.~Varoquaux.
NeuMiss networks: differentiable programming for supervised learning with missing values.
\textit{NeurIPS}, 5980--5990, 2020.

\bibitem{lemorvan2021}
M.~Le~Morvan, J.~Josse, E.~Scornet, G.~Varoquaux.
What's a good imputation to predict with missing values?
\textit{NeurIPS}, 11530--11540, 2021.

\bibitem{saar-tsechansky2009}
M.~Saar-Tsechansky, P.~Melville, F.~Provost.
Active feature-value acquisition.
\textit{Management Science}, 55(4):664--684, 2009.

\bibitem{rubin1976}
D.~B.~Rubin.
Inference and missing data.
\textit{Biometrika}, 63(3):581--592, 1976.

\bibitem{sobol1967}
I.~M.~Sobol.
On the distribution of points in a cube and the approximate evaluation of integrals.
\textit{USSR Computational Mathematics and Mathematical Physics}, 7(4):86--112, 1967.

\end{thebibliography}

\end{document}
