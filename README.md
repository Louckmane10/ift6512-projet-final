# DRO for Feature Acquisition with Missing Data

[![Julia](https://img.shields.io/badge/Julia-1.9+-blue.svg)](https://julialang.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Projet Final IFT6512 â€” Programmation Stochastique**  
> UniversitÃ© de MontrÃ©al, DÃ©cembre 2025

## ğŸ“‹ Description

Ce projet implÃ©mente une approche **distributionnellement robuste (DRO)** pour l'apprentissage supervisÃ© avec **donnÃ©es manquantes** et **acquisition de caractÃ©ristiques sous contrainte de budget**.

### ProblÃ©matique

En diagnostic mÃ©dical, les donnÃ©es manquantes suivent souvent un mÃ©canisme **MNAR** (Missing Not At Random) : un mÃ©decin prescrit un test parce qu'il suspecte un problÃ¨me, donc le fait qu'une valeur soit manquante dÃ©pend de la valeur elle-mÃªme. Ce mÃ©canisme est **non-identifiable**, ce qui rend les mÃ©thodes d'imputation classiques vulnÃ©rables.

### Solution proposÃ©e

Notre approche utilise la **DRO avec ensemble d'ambiguÃ¯tÃ© de Wasserstein** pour :
1. ConsidÃ©rer un ensemble de distributions plausibles autour de la distribution de rÃ©fÃ©rence
2. Optimiser pour le **pire cas** dans cet ensemble
3. DÃ©cider quelles caractÃ©ristiques acquÃ©rir sous contrainte de budget

## ğŸš€ Installation

### PrÃ©requis

- Julia 1.9 ou supÃ©rieur

### Installation

```bash
git clone https://github.com/VOTRE_USERNAME/dro-missing-data.git
cd dro-missing-data
julia run_experiments.jl
```

## ğŸ“ Structure du projet

```
dro-missing-data/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scenario_generation.jl   # GÃ©nÃ©ration de scÃ©narios (Gaussien, MICE)
â”‚   â”œâ”€â”€ dro_objective.jl         # Ã‰valuation de l'objectif DRO
â”‚   â”œâ”€â”€ acquisition_solver.jl    # Optimisation combinatoire
â”‚   â”œâ”€â”€ saa_dro.jl               # Algorithme SAA-DRO principal
â”‚   â”œâ”€â”€ baselines.jl             # MÃ©thodes de comparaison
â”‚   â””â”€â”€ utils.jl                 # Utilitaires (donnÃ©es, mÃ©triques)
â”œâ”€â”€ rapport/
â”‚   â””â”€â”€ projet_final.tex         # Rapport LaTeX (~50 pages)
â”œâ”€â”€ run_experiments.jl           # Script principal
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## ğŸ’» Utilisation

```bash
julia run_experiments.jl all    # Toutes les expÃ©riences
julia run_experiments.jl 1      # Exp 1: Comparaison mÃ©canismes
julia run_experiments.jl 2      # Exp 2: SensibilitÃ© Ã  epsilon
julia run_experiments.jl 3      # Exp 3: Valeur de l'information
julia run_experiments.jl 4      # Exp 4: Convergence SAA
julia run_experiments.jl 5      # Exp 5: SensibilitÃ© au budget
```

## ğŸ“Š RÃ©sultats principaux

| MÃ©thode | MCAR | MNAR+ | Î” robustesse |
|---------|------|-------|--------------|
| Greedy-NR | 0.462 | 0.538 | 0.076 |
| **DRO (Îµ=0.1)** | **0.472** | **0.498** | **0.026** |

- âœ… DRO surpasse les baselines de **7-9%** sous MNAR
- âœ… Ã‰cart de robustesse rÃ©duit de **3Ã—**

## ğŸ“ Formulation

```
min_z  max_{P âˆˆ P_Îµ}  E_P[â„“(y, f_Î¸(xÌƒ(z, Î¾)))]
s.t.   Î£ c_j z_j â‰¤ B,  z_j âˆˆ {0,1}
```

## ğŸ“š RÃ©fÃ©rences

- Kuhn et al. (2024). *Distributionally robust optimization*. Acta Numerica.
- Le Morvan et al. (2021). *What's a good imputation?* NeurIPS.

## ğŸ“„ License

MIT License - Usage acadÃ©mique.

---
**Auteur:** Louck | **Cours:** IFT6512 | **Date:** DÃ©cembre 2025
